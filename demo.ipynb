{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from videograph import VideoGraph\n",
    "from utils.general import *\n",
    "from utils.video_processing import *\n",
    "from utils.chat_api import *\n",
    "from prompts import *\n",
    "\n",
    "from face_processing import process_faces\n",
    "from voice_processing import process_voices\n",
    "from memory_processing import (\n",
    "    process_captions,\n",
    "    generate_captions_and_thinkings_with_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(video_graph, base64_video, base64_frames, base64_audio):\n",
    "\n",
    "    id2voices = process_voices(video_graph, base64_audio, base64_video)\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    print(f\"processing {len(base64_frames)} frames...\")\n",
    "\n",
    "    id2faces = process_faces(video_graph, base64_frames)\n",
    "    # print(id2faces.keys())\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    episodic_captions, semantic_captions = generate_captions_and_thinkings_with_ids(\n",
    "        video_graph,\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        base64_audio,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "    )\n",
    "\n",
    "    process_captions(video_graph, episodic_captions, type=\"episodic\")\n",
    "    process_captions(video_graph, semantic_captions, type=\"semantic\")\n",
    "\n",
    "    print(\"Finish processing segment\")\n",
    "\n",
    "\n",
    "def streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds, fps, segment_limit=None\n",
    "):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file or directory containing clips\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "    if os.path.isfile(video_path):\n",
    "        # Process single video file\n",
    "        video_info = get_video_info(video_path)\n",
    "        print(video_info)\n",
    "\n",
    "        # Process each interval\n",
    "        count = 0\n",
    "        for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "            if start_time + interval_seconds > video_info[\"duration\"]:\n",
    "                break\n",
    "\n",
    "            print(\"=\" * 20)\n",
    "            count += 1\n",
    "\n",
    "            print(f\"Loading {count}-th clip starting at {start_time} seconds...\")\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                video_path, start_time, interval_seconds, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            # check dtype\n",
    "            # print(type(base64_video), type(base64_frames[0]), type(base64_audio))\n",
    "\n",
    "            # Process frames for this interval\n",
    "            if base64_frames:\n",
    "                print(\n",
    "                    f\"Starting processing {count}-th clip starting at {start_time} seconds...\"\n",
    "                )\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break\n",
    "\n",
    "    elif os.path.isdir(video_path):\n",
    "        # Process directory of numbered clips\n",
    "        files = os.listdir(video_path)\n",
    "        # Filter for video files and sort by numeric value in filename\n",
    "        video_files = [\n",
    "            f for f in files if any(f.endswith(ext) for ext in [\".mp4\", \".avi\", \".mov\"])\n",
    "        ]\n",
    "        video_files.sort(key=lambda x: int(\"\".join(filter(str.isdigit, x))))\n",
    "\n",
    "        for count, video_file in enumerate(video_files, 1):\n",
    "            print(\"=\" * 20)\n",
    "            full_path = os.path.join(video_path, video_file)\n",
    "            print(f\"Processing clip {count}: {full_path}\")\n",
    "\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                full_path, 0, None, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            if base64_frames:\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_config = json.load(open(\"configs/processing_config.json\"))\n",
    "memory_config = json.load(open(\"configs/memory_config.json\"))\n",
    "# video paths can be paths to directories or paths to mp4 files\n",
    "video_paths = processing_config[\"video_paths\"]\n",
    "\n",
    "for video_path in video_paths:\n",
    "\n",
    "    video_graph = VideoGraph(**memory_config)\n",
    "\n",
    "    streaming_process_video(\n",
    "        video_graph,\n",
    "        video_path,\n",
    "        processing_config[\"interval_seconds\"],\n",
    "        processing_config[\"fps\"],\n",
    "        processing_config[\"segment_limit\"],\n",
    "    )\n",
    "\n",
    "    save_dir = \"data/video_graphs\"\n",
    "    save_video_graph(\n",
    "        video_graph, video_path, save_dir, (processing_config, memory_config)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph_path = \"data/video_graphs/5-Poor-People-vs-1-Secret-Millionaire_60_5_5_10_20_0.3_0.6_0.75.pkl\"\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "# for text_node in video_graph.text_nodes:\n",
    "#     print(video_graph.nodes[text_node].metadata['contents'])\n",
    "# for nodes, weight in video_graph.edges.items():\n",
    "#     if weight > 1:\n",
    "#         if video_graph.nodes[nodes[0]].type in [\"episodic\", \"semantic\"]:\n",
    "#            print(video_graph.nodes[nodes[0]].metadata['contents'])\n",
    "#         else:\n",
    "#            print(video_graph.nodes[nodes[1]].metadata['contents'])\n",
    "#         print(weight)\n",
    "\n",
    "equivalences = video_graph.extract_equivalences()\n",
    "print(equivalences)\n",
    "           \n",
    "# video_graph.summarize(logging=True)\n",
    "# save_dir = \"data/video_graphs\"\n",
    "# save_video_graph(\n",
    "#     video_graph, None, save_dir, None, file_name='5-Poor-People-vs-1-Secret-Millionaire_60_5_5_10_20_0.3_0.6_0.75_augmented.pkl'\n",
    "# )\n",
    "# video_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from retrieve import retrieve_from_videograph\n",
    "# from videograph import VideoGraph\n",
    "# from utils.chat_api import (\n",
    "#     generate_messages,\n",
    "#     get_response_with_retry,\n",
    "#     parallel_get_embedding,\n",
    "# )\n",
    "# from utils.general import validate_and_fix_python_list\n",
    "# from prompts import prompt_memory_retrieval\n",
    "\n",
    "# MAX_RETRIES = 3\n",
    "\n",
    "\n",
    "# def generate_queries(question, existing_knowledge=None, query_num=1):\n",
    "#     input = [\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"content\": prompt_memory_retrieval.format(\n",
    "#                 question=question,\n",
    "#                 query_num=query_num,\n",
    "#                 existing_knowledge=existing_knowledge,\n",
    "#             ),\n",
    "#         }\n",
    "#     ]\n",
    "#     messages = generate_messages(input)\n",
    "#     model = \"gpt-4o-2024-11-20\"\n",
    "#     queries = None\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         print(f\"Generating queries {i} times\")\n",
    "#         queries = get_response_with_retry(model, messages)[0]\n",
    "#         queries = validate_and_fix_python_list(queries)\n",
    "#         if queries is not None:\n",
    "#             break\n",
    "#     if queries is None:\n",
    "#         raise Exception(\"Failed to generate queries\")\n",
    "#     return queries\n",
    "\n",
    "\n",
    "# def retrieve_from_videograph(videograph, question, topk=3):\n",
    "#     queries = generate_queries(question)\n",
    "#     print(f\"Queries: {queries}\")\n",
    "\n",
    "#     model = \"text-embedding-3-large\"\n",
    "#     query_embeddings = parallel_get_embedding(model, queries)[0]\n",
    "\n",
    "#     related_nodes = []\n",
    "\n",
    "#     for query_embedding in query_embeddings:\n",
    "#         nodes = videograph.search_text_nodes(query_embedding)\n",
    "#         related_nodes.extend(nodes)\n",
    "\n",
    "#     related_nodes = list(set(related_nodes))\n",
    "#     return related_nodes\n",
    "\n",
    "\n",
    "# question = \"Denny\"\n",
    "# retrieved_nodes = retrieve_from_videograph(video_graph, question)\n",
    "# print(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
