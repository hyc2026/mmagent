{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://bytedpypi.byted.org/simple/\n",
      "Collecting bytedeuler\n",
      "  Using cached https://bytedpypi.byted.org/packages/bytedeuler/bytedeuler-2.7.3.tar.gz (122 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Using cached https://bytedpypi.byted.org/packages/opencv-python-headless/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (10.2.0)\n",
      "Collecting matplotlib\n",
      "  Using cached https://bytedpypi.byted.org/packages/matplotlib/matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Collecting pydub\n",
      "  Using cached https://bytedpypi.byted.org/packages/pydub/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached https://bytedpypi.byted.org/packages/scikit-learn/scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Collecting tqdm\n",
      "  Using cached https://bytedpypi.byted.org/packages/tqdm/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting openai\n",
      "  Using cached https://bytedpypi.byted.org/packages/openai/openai-1.66.5-py3-none-any.whl (571 kB)\n",
      "Collecting moviepy\n",
      "  Using cached https://bytedpypi.byted.org/packages/moviepy/moviepy-2.1.2-py3-none-any.whl (126 kB)\n",
      "Collecting bytedtos\n",
      "  Using cached https://bytedpypi.byted.org/packages/bytedtos/bytedtos-1.1.19.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bytedlaplace\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedlaplace/bytedlaplace-0.9.60-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: bytedance.context~=0.3 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.7.1)\n",
      "Collecting bytedance.versioncollect<1.0.0,>=0.0.1 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedance-versioncollect/bytedance.versioncollect-0.2.0.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bytedbackgrounds<1.0.0,>=0.0.2 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.0.6)\n",
      "Requirement already satisfied: byteddps<1.0.0,>=0.0.9 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.1.2)\n",
      "Requirement already satisfied: bytedenv<1.0.0,>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.6.4)\n",
      "Collecting bytedlogger<1.0.0,>=0.10.0 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedlogger/bytedlogger-0.15.2.tar.gz (182 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bytedlogid<1.0.0,>=0.0.2 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedlogid/bytedlogid-0.2.1.tar.gz (5.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bytedance.metrics<1.0.0,>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.5.2)\n",
      "Requirement already satisfied: bytedservicediscovery~=0.17 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (0.18.0)\n",
      "Collecting bytedtrace<1.0.0,>=0.2.0 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedtrace/bytedtrace-0.3.0.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gevent<25.0.0,>=1.0.1 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/gevent/gevent-24.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gunicorn<21,>=19 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/gunicorn/gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting psutil<=6.0.0,>=5.6.0 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/psutil/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.9/dist-packages (from bytedeuler) (2.32.3)\n",
      "Requirement already satisfied: six<2.0.0,>=1.13.0 in /usr/lib/python3/dist-packages (from bytedeuler) (1.16.0)\n",
      "Collecting thriftpy2<1.0.0,>=0.4.20 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/thriftpy2/thriftpy2-0.5.2.tar.gz (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from opencv-python-headless) (1.26.4)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/contourpy/contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/cycler/cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/fonttools/fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/kiwisolver/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (24.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pyparsing/pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/importlib-resources/importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading https://bytedpypi.byted.org/packages/scipy/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading https://bytedpypi.byted.org/packages/joblib/joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading https://bytedpypi.byted.org/packages/threadpoolctl/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/distro/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/httpx/httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/jiter/jiter-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pydantic/pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.9/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (5.1.1)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading https://bytedpypi.byted.org/packages/imageio/imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading https://bytedpypi.byted.org/packages/imageio-ffmpeg/imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading https://bytedpypi.byted.org/packages/proglog/proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /usr/local/lib/python3.9/dist-packages (from moviepy) (1.0.1)\n",
      "Collecting crcmod<2.0,>=1.7 (from bytedtos)\n",
      "  Downloading https://bytedpypi.byted.org/packages/crcmod/crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fire<1.0.0,>=0.2.1 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/fire/fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: deprecated<2.0.0,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from bytedlaplace) (1.2.15)\n",
      "Collecting bytedquicksilver<3.0.0,>=2.1.2.2 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedquicksilver/bytedquicksilver-2.2.0.15.tar.gz (56 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting prettytable<3.0.0,>=2.0.0 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/prettytable/prettytable-2.5.0-py3-none-any.whl (24 kB)\n",
      "Collecting bytedance.servicediscovery<=0.1.2,>=0.1.2 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedance-servicediscovery/bytedance.servicediscovery-0.1.2-py2.py3-none-any.whl (1.5 kB)\n",
      "Collecting grpcio-tools<=1.56.0,>=1.48.0 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thriftpy2<1.0.0,>=0.4.20 (from bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/thriftpy2/thriftpy2-0.5.1a1.tar.gz (780 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  WARNING: Requested thriftpy2<1.0.0,>=0.4.20 from https://bytedpypi.byted.org/packages/thriftpy2/thriftpy2-0.5.1a1.tar.gz#sha256=1820bcd0a2125368a805cd09066979ba47edbfe4baa71bf763979cfa32557f39 (from bytedeuler), but installing version 0.5.1a1\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: msgpack<1.1.0,>=0.5.6 in /usr/local/lib/python3.9/dist-packages (from bytedance.metrics<1.0.0,>=0.5.1->bytedeuler) (1.0.8)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from bytedance.versioncollect<1.0.0,>=0.0.1->bytedeuler) (1.26.20)\n",
      "Requirement already satisfied: schedule<2.0.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from bytedbackgrounds<1.0.0,>=0.0.2->bytedeuler) (1.2.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from byteddps<1.0.0,>=0.0.9->bytedeuler) (2.10.1)\n",
      "Requirement already satisfied: ipaddress<2.0.0,>=1.0.10 in /usr/local/lib/python3.9/dist-packages (from bytedenv<1.0.0,>=0.3.1->bytedeuler) (1.0.23)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.11 in /usr/local/lib/python3.9/dist-packages (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace) (3.20.3)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/typeguard/typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting absl-py<3.0.0,>=0.9.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/absl-py/absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting pandas<2.0.0,>=1.0.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pandas/pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate<1.0.0,>=0.8.7 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/tabulate/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting termcolor<2.0.0,>=1.1.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/termcolor/termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting openpyxl<4.0.0,>=3.0.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/openpyxl/openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Collecting wget<4.0.0,>=3.0.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/wget/wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting packaging>=20.0 (from matplotlib)\n",
      "  Downloading https://bytedpypi.byted.org/packages/packaging/packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting jsonschema<4.0.0,>=3.2.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/jsonschema/jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting pynvml<12.0.0,>=11.5.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pynvml/pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "Collecting addict<3.0.0,>=2.4.0 (from bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/addict/addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting bytedtcc<2.0.0,>=1.2.0 (from bytedtrace<1.0.0,>=0.2.0->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/bytedtcc/bytedtcc-1.4.5.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from deprecated<2.0.0,>=1.2.0->bytedlaplace) (1.17.0)\n",
      "Collecting zope.event (from gevent<25.0.0,>=1.0.1->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/zope-event/zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface (from gevent<25.0.0,>=1.0.1->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/zope-interface/zope.interface-7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253 kB)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.9/dist-packages (from gevent<25.0.0,>=1.0.1->bytedeuler) (3.1.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools<=1.56.0,>=1.48.0 (from bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.55.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.54.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.54.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.54.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.53.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.53.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.50.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.49.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://bytedpypi.byted.org/packages/grpcio-tools/grpcio_tools-1.48.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from grpcio-tools<=1.56.0,>=1.48.0->bytedlaplace) (1.69.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from grpcio-tools<=1.56.0,>=1.48.0->bytedlaplace) (74.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/httpcore/httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/h11/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prettytable<3.0.0,>=2.0.0->bytedlaplace) (0.2.13)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/annotated-types/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pydantic-core/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.19.1->bytedeuler) (3.3.2)\n",
      "Collecting ply<4.0,>=3.4 (from thriftpy2<1.0.0,>=0.4.20->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/ply/ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Collecting python-etcd<1.0.0,>=0.4.5 (from bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/python-etcd/python-etcd-0.4.5.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bytedztijwthelper<1.0.0,>=0.0.19 in /usr/local/lib/python3.9/dist-packages (from bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.0.23)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema<4.0.0,>=3.2.0->bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace) (24.3.0)\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema<4.0.0,>=3.2.0->bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pyrsistent/pyrsistent-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.0.0->bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/et-xmlfile/et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.0.0,>=1.0.0->bytedquicksilver<3.0.0,>=2.1.2.2->bytedlaplace)\n",
      "  Downloading https://bytedpypi.byted.org/packages/pytz/pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Requirement already satisfied: bytedztispiffe<1.0.0,>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.0.15)\n",
      "Requirement already satisfied: bytedmemfd<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.2)\n",
      "Collecting dnspython>=1.13.0 (from python-etcd<1.0.0,>=0.4.5->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler)\n",
      "  Downloading https://bytedpypi.byted.org/packages/dnspython/dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.4 in /usr/local/lib/python3.9/dist-packages (from bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (42.0.8)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=22.0.0 in /usr/local/lib/python3.9/dist-packages (from bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (24.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography<43.0.0,>=3.4->bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=3.4->bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (2.22)\n",
      "Building wheels for collected packages: bytedeuler, bytedtos, bytedance.versioncollect, bytedlogger, bytedlogid, bytedquicksilver, bytedtrace, crcmod, fire, thriftpy2, bytedtcc, termcolor, wget, python-etcd\n",
      "  Building wheel for bytedeuler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedeuler: filename=bytedeuler-2.7.3-cp39-cp39-linux_x86_64.whl size=349681 sha256=05175176ffd09766fc2dd3e05159a59938f7c5ece4d7a1b70c62607da7d04200\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/0d/1c/ccaa86112ccd11a30d52b6703fa67762cc2fce2d74273262bc\n",
      "  Building wheel for bytedtos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedtos: filename=bytedtos-1.1.19-py3-none-any.whl size=24527 sha256=4656c40ffa6735261f1495a3c6e24a1f137876f2a7d5c844ecb8824ca19c9548\n",
      "  Stored in directory: /root/.cache/pip/wheels/60/2d/00/e95fb8c2831e8570bcc9d2d52f54a2bb26f8dfd2222e8f960c\n",
      "  Building wheel for bytedance.versioncollect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedance.versioncollect: filename=bytedance.versioncollect-0.2.0-py3-none-any.whl size=4141 sha256=0d8e5f1969dc8f92823d96d7fb62257265977df5f50f25129db9233f8292bf8f\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/0c/5b/753be12019fcc23423ed0bf0830480036d14b22984c66fa245\n",
      "  Building wheel for bytedlogger (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedlogger: filename=bytedlogger-0.15.2-cp39-cp39-linux_x86_64.whl size=685935 sha256=2c2c5a103981f1fd50ef8f43015fcaa8694a0a9f882a7d6dc654231db0f0ff36\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/2d/58/9b8ebf8becafcc3f0e5f9e8239d02d7d6798ec2ff9d86c1696\n",
      "  Building wheel for bytedlogid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedlogid: filename=bytedlogid-0.2.1-py3-none-any.whl size=5133 sha256=9f18e1fdb65ed809b597e1db871b37c05ccdbac7017816247ea935e6a838026a\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/e4/49/2c43b8925e32f25af4bd14ec0fb137049f06bfbc0dd3a453fc\n",
      "  Building wheel for bytedquicksilver (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedquicksilver: filename=bytedquicksilver-2.2.0.15-py3-none-any.whl size=74077 sha256=e0dc5a1d6c7243acc770ac47cdc3166249098849863bb111b24b38569e8f3e73\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/4c/2d/791f5103f62e02cee18c24c9e8010b6da0ec9cce1e46db26cf\n",
      "  Building wheel for bytedtrace (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedtrace: filename=bytedtrace-0.3.0-py3-none-any.whl size=65347 sha256=1da8467cdf916dbbcf288889d4ede08a4cec870671639efd85f7279cba460199\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/e7/70/38e2ff031a0b57859f6e49db69786aff44b445c0aec06f9e59\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=31334 sha256=d7e33220dcf764185320659ab12b5f8d8d9216726800f6558bad706964cbbb6e\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/59/27/c1e5865c6aa02ad248c5c46877094c713e51e5d5ba12e49e97\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=fe13018c1a0d354967bc498a2b5be54ef47e06f7be36eb21131528e576b3511b\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/32/e2/7e8ae4cb08cea6779ca5d0e623c2cc29b08600812d95eed534\n",
      "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thriftpy2: filename=thriftpy2-0.5.1a1-cp39-cp39-linux_x86_64.whl size=1768968 sha256=1d8b8bf19d1eebdcf4fb93376c785d0fee6df95734ecdd2385c0988b1b329945\n",
      "  Stored in directory: /root/.cache/pip/wheels/6f/6c/0b/1d116da9e8c4ad28b699b74b825fe78e907b1a665bd89a7ec2\n",
      "  Building wheel for bytedtcc (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bytedtcc: filename=bytedtcc-1.4.5-py3-none-any.whl size=23546 sha256=57324178416c17cd61b2663a8390e5d4c702c828dd10a2d9d44ebff0f72c2ac1\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/e5/d3/2c62ebfe366525eda12e62dd7b4587eaa7d2888513dedf7da8\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=b92595cf82b43ccbe9d65aa1b030c2d447844c67d2b30128541a6261e7a15694\n",
      "  Stored in directory: /root/.cache/pip/wheels/b6/96/38/bcecb3212fbfffc93c6ead19617d414952e66abad97464b769\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=cb9329a51d4bc7b894294b35de931273df9a015e40bbe01171387964468fc823\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/9d/5e/980c6d72895c57e42f46a5bd5f1b29fdfdf637733b66ffe0c9\n",
      "  Building wheel for python-etcd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-etcd: filename=python_etcd-0.4.5-py3-none-any.whl size=38479 sha256=26c57539b0ab42a3b5711d5f34c97706c40f2ccb5763294ce3f8252938fec09a\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/1b/4d/48c9286121aaf449c814cb9d2b7000b729486c8180c88bbada\n",
      "Successfully built bytedeuler bytedtos bytedance.versioncollect bytedlogger bytedlogid bytedquicksilver bytedtrace crcmod fire thriftpy2 bytedtcc termcolor wget python-etcd\n",
      "\u001b[33mWARNING: Error parsing dependencies of gpg: Invalid version: '1.14.0-unknown'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wget, termcolor, pytz, pydub, ply, crcmod, addict, zope.interface, zope.event, typeguard, tqdm, thriftpy2, threadpoolctl, tabulate, scipy, pyrsistent, pyparsing, pynvml, pydantic-core, psutil, prettytable, packaging, opencv-python-headless, kiwisolver, joblib, jiter, importlib-resources, imageio_ffmpeg, imageio, h11, gunicorn, grpcio-tools, fonttools, fire, et-xmlfile, dnspython, distro, cycler, contourpy, annotated-types, absl-py, scikit-learn, python-etcd, pydantic, proglog, pandas, openpyxl, matplotlib, jsonschema, httpcore, gevent, bytedlogid, moviepy, httpx, bytedance.versioncollect, bytedance.servicediscovery, openai, bytedlogger, bytedtcc, bytedtrace, bytedtos, bytedeuler, bytedquicksilver, bytedlaplace\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.1.1\n",
      "    Uninstalling psutil-6.1.1:\n",
      "      Successfully uninstalled psutil-6.1.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.23.0\n",
      "    Uninstalling jsonschema-4.23.0:\n",
      "      Successfully uninstalled jsonschema-4.23.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlx-python-sdk 0.3.0 requires datasets>=1.15.0, which is not installed.\n",
      "mlx-python-sdk 0.3.0 requires huggingface-hub>=0.0.19, which is not installed.\n",
      "mlx-python-sdk 0.3.0 requires pyarrow>=5.0, which is not installed.\n",
      "jupyter-events 0.11.0 requires jsonschema[format-nongpl]>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "jupyterlab-server 2.27.3 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mlx-python-sdk 0.3.0 requires bytedmetrics==0.9.*, but you have bytedmetrics 0.10.2 which is incompatible.\n",
      "mlx-python-sdk 0.3.0 requires fsspec==2022.*, but you have fsspec 2024.6.1 which is incompatible.\n",
      "mlx-python-sdk 0.3.0 requires packaging~=21.3, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 addict-2.4.0 annotated-types-0.7.0 bytedance.servicediscovery-0.1.2 bytedance.versioncollect-0.2.0 bytedeuler-2.7.3 bytedlaplace-0.9.60 bytedlogger-0.15.2 bytedlogid-0.2.1 bytedquicksilver-2.2.0.15 bytedtcc-1.4.5 bytedtos-1.1.19 bytedtrace-0.3.0 contourpy-1.3.0 crcmod-1.7 cycler-0.12.1 distro-1.9.0 dnspython-2.7.0 et-xmlfile-2.0.0 fire-0.7.0 fonttools-4.56.0 gevent-24.11.1 grpcio-tools-1.48.2 gunicorn-20.1.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 imageio-2.37.0 imageio_ffmpeg-0.6.0 importlib-resources-6.5.2 jiter-0.9.0 joblib-1.4.2 jsonschema-3.2.0 kiwisolver-1.4.7 matplotlib-3.9.4 moviepy-2.1.2 openai-1.66.5 opencv-python-headless-4.11.0.86 openpyxl-3.1.5 packaging-23.2 pandas-1.5.3 ply-3.11 prettytable-2.5.0 proglog-0.1.10 psutil-6.0.0 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 pynvml-11.5.3 pyparsing-3.2.1 pyrsistent-0.20.0 python-etcd-0.4.5 pytz-2025.1 scikit-learn-1.6.1 scipy-1.13.1 tabulate-0.9.0 termcolor-1.1.0 threadpoolctl-3.6.0 thriftpy2-0.5.1a1 tqdm-4.67.1 typeguard-2.13.3 wget-3.2 zope.event-5.0 zope.interface-7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bytedeuler opencv-python-headless pillow matplotlib pydub scikit-learn tqdm openai moviepy bytedtos bytedlaplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import euler\n",
    "\n",
    "euler.install_thrift_import_hook()\n",
    "\n",
    "from idl.base_thrift import *\n",
    "from idl.face_processing_thrift import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "import ast\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from pydub import AudioSegment\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "from videograph import VideoGraph\n",
    "from utils.general import *\n",
    "from utils.video_processing import *\n",
    "from utils.chat_api import *\n",
    "from prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build client\n",
    "# test_client = euler.Client(FaceService, 'tcp://127.0.0.1:8910', timeout=300, transport='buffered')\n",
    "test_client = euler.Client(\n",
    "    FaceService,\n",
    "    \"sd://lab.agent.face_processing_test?idc=maliva&cluster=default\",\n",
    "    timeout=300,\n",
    "    transport=\"buffered\",\n",
    ")\n",
    "\n",
    "CLUSTER_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the given faces are recognizable\n",
    "def batch_classify_faces(faces):\n",
    "    print(len(faces))\n",
    "    base64_faces = [face[\"extra_data\"][\"face_base64\"] for face in faces]\n",
    "    inputs = [\n",
    "        [\n",
    "            {\"type\": \"images\", \"content\": [base64_face]},\n",
    "            {\"type\": \"text\", \"content\": prompt_classify_recognizable_faces},\n",
    "        ]\n",
    "        for base64_face in base64_faces\n",
    "    ]\n",
    "    messages = [generate_messages(input) for input in inputs]\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = parallel_get_response(model, messages)\n",
    "    for i in range(len(response[0])):\n",
    "        faces[i][\"extra_data\"][\"recognizable\"] = int(response[0][i])\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_representative_faces_with_rules(faces):\n",
    "    \"\"\"Select the most representative face for each cluster based on face type, size and similarity.\n",
    "\n",
    "    Args:\n",
    "        faces (list): List of face dictionaries containing frame_id, bounding_box, face_emb,\n",
    "                     cluster_id and extra_data with face_type\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of cluster_id to the most representative face\n",
    "    \"\"\"\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    representative_faces = {}\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        # First try to find ortho faces\n",
    "        ortho_faces = []\n",
    "        side_faces = []\n",
    "        for f in cluster_faces:\n",
    "            if f[\"extra_data\"][\"face_type\"] == \"ortho\":\n",
    "                ortho_faces.append(f)\n",
    "            else:\n",
    "                side_faces.append(f)\n",
    "\n",
    "        if ortho_faces:\n",
    "            # For ortho faces, first select top 10% by size\n",
    "            areas = [\n",
    "                (\n",
    "                    f,\n",
    "                    (f[\"bounding_box\"][2] - f[\"bounding_box\"][0])\n",
    "                    * (f[\"bounding_box\"][3] - f[\"bounding_box\"][1]),\n",
    "                )\n",
    "                for f in ortho_faces\n",
    "            ]\n",
    "            areas.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_size_faces = [f[0] for f in areas[: max(1, int(len(areas) * 0.1))]]\n",
    "\n",
    "            # If only one face remains, use it directly\n",
    "            if len(top_size_faces) == 1:\n",
    "                best_face = top_size_faces[0]\n",
    "            else:\n",
    "                # Find the one with highest average similarity to all faces in cluster\n",
    "                max_avg_similarity = -1\n",
    "                best_face = None\n",
    "                cluster_embeddings = np.array(\n",
    "                    [face[\"face_emb\"] for face in cluster_faces]\n",
    "                )\n",
    "\n",
    "                for face in top_size_faces:\n",
    "                    similarities = np.dot(cluster_embeddings, face[\"face_emb\"])\n",
    "                    avg_similarity = (np.sum(similarities) - 1) / (\n",
    "                        len(cluster_faces) - 1\n",
    "                    )\n",
    "                    if avg_similarity > max_avg_similarity:\n",
    "                        max_avg_similarity = avg_similarity\n",
    "                        best_face = face\n",
    "\n",
    "        else:\n",
    "            # For side faces, first select top 20% by aspect ratio closest to 1\n",
    "            if side_faces:\n",
    "                areas = [\n",
    "                    (\n",
    "                        f,\n",
    "                        (f[\"bounding_box\"][2] - f[\"bounding_box\"][0])\n",
    "                        * (f[\"bounding_box\"][3] - f[\"bounding_box\"][1]),\n",
    "                    )\n",
    "                    for f in side_faces\n",
    "                ]\n",
    "                areas.sort(key=lambda x: x[1], reverse=True)\n",
    "                top_area_faces = [f[0] for f in areas[: max(1, int(len(areas) * 0.5))]]\n",
    "\n",
    "                # Then select top 20% by aspect ratio closest to 1\n",
    "                ratios = []\n",
    "                for face in top_area_faces:\n",
    "                    bbox = face[\"bounding_box\"]\n",
    "                    width = bbox[2] - bbox[0]\n",
    "                    height = bbox[3] - bbox[1]\n",
    "                    ratio = abs(width / height - 1.0)\n",
    "                    ratios.append((face, ratio))\n",
    "\n",
    "                ratios.sort(key=lambda x: x[1])  # Sort by ratio difference from 1\n",
    "                final_candidates = [\n",
    "                    f[0] for f in ratios[: max(1, int(len(ratios) * 0.2))]\n",
    "                ]\n",
    "\n",
    "                # If only one face remains, use it directly\n",
    "                if len(final_candidates) == 1:\n",
    "                    best_face = final_candidates[0]\n",
    "                else:\n",
    "                    # Find the one with highest average similarity to all faces in cluster\n",
    "                    max_avg_similarity = -1\n",
    "                    best_face = None\n",
    "                    cluster_embeddings = np.array(\n",
    "                        [face[\"face_emb\"] for face in cluster_faces]\n",
    "                    )\n",
    "\n",
    "                    for face in final_candidates:\n",
    "                        similarities = np.dot(cluster_embeddings, face[\"face_emb\"])\n",
    "                        avg_similarity = (np.sum(similarities) - 1) / (\n",
    "                            len(cluster_faces) - 1\n",
    "                        )\n",
    "                        if avg_similarity > max_avg_similarity:\n",
    "                            max_avg_similarity = avg_similarity\n",
    "                            best_face = face\n",
    "\n",
    "        representative_faces[cluster_id] = best_face\n",
    "\n",
    "    # return representative_faces\n",
    "\n",
    "    faces_list = []\n",
    "    for cluster_id, face in representative_faces.items():\n",
    "        faces_list.append(face)\n",
    "    return faces_list\n",
    "\n",
    "\n",
    "def select_representative_faces_with_scores(faces, max_faces=3):\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    faces_list = []\n",
    "    faces_per_cluster = {}\n",
    "    dthresh = 0.85\n",
    "    qthresh = 22\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        qualified_faces = [\n",
    "            face\n",
    "            for face in cluster_faces\n",
    "            if float(face[\"extra_data\"][\"face_detection_score\"]) > dthresh\n",
    "            and float(face[\"extra_data\"][\"face_quality_score\"]) > qthresh\n",
    "        ]\n",
    "        if qualified_faces:\n",
    "            # Sort faces by face_detection_score and face_quality_score\n",
    "            sorted_faces = sorted(\n",
    "                qualified_faces,\n",
    "                key=lambda x: (\n",
    "                    float(x[\"extra_data\"][\"face_detection_score\"]),\n",
    "                    float(x[\"extra_data\"][\"face_quality_score\"]),\n",
    "                ),\n",
    "                reverse=True,\n",
    "            )\n",
    "            # Select the face with the highest face_detection_score and face_quality_score\n",
    "            best_faces = sorted_faces[:max_faces]\n",
    "            faces_per_cluster[cluster_id] = best_faces\n",
    "            faces_list.append(best_faces)\n",
    "\n",
    "    return faces_list\n",
    "    # return faces_per_cluster\n",
    "\n",
    "\n",
    "def select_representative_faces_with_gpt(faces):\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    faces_list = []\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        faces_base64 = [face[\"extra_data\"][\"face_base64\"] for face in cluster_faces]\n",
    "        print(f\"faces number: {len(faces_base64)}\")\n",
    "        # model = 'gemini-1.5-pro-002'\n",
    "        # input = [\n",
    "        #     {\n",
    "        #         \"type\": \"images\",\n",
    "        #         \"content\": faces_base64,\n",
    "        #     },\n",
    "        #     {\n",
    "        #         \"type\": \"text\",\n",
    "        #         \"content\": prompt_select_representative_faces,\n",
    "        #     }\n",
    "        # ]\n",
    "        model = \"gpt-4o-2024-11-20\"\n",
    "        input = [\n",
    "            {\n",
    "                \"type\": \"images\",\n",
    "                \"content\": faces_base64,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": prompt_select_representative_faces_forced,\n",
    "            },\n",
    "        ]\n",
    "        messages = generate_messages(input)\n",
    "\n",
    "        response = get_response_with_retry(model, messages)\n",
    "        try:\n",
    "            index = int(response[0])\n",
    "            if index >= 0:\n",
    "                print(f\"best face: {index}\")\n",
    "                faces_list.append(cluster_faces[index])\n",
    "            else:\n",
    "                print(f\"cannot find a good face\")\n",
    "                # insert a face with black base64\n",
    "                size = (100, 100)\n",
    "                black_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
    "                buffered = BytesIO()\n",
    "                black_image.save(buffered, format=\"JPEG\")\n",
    "                img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "                black_face = {\n",
    "                    \"frame_id\": -1,\n",
    "                    \"bounding_box\": [0, 0, 0, 0],\n",
    "                    \"face_emb\": np.zeros_like(cluster_faces[0][\"face_emb\"]).tolist(),\n",
    "                    \"cluster_id\": -1,\n",
    "                    \"extra_data\": {\"face_type\": \"other\", \"face_base64\": img_base64},\n",
    "                }\n",
    "                faces_list.append(black_face)\n",
    "        except:\n",
    "            print(f\"cannot find a good face\")\n",
    "            # insert a face with black base64\n",
    "            size = (100, 100)\n",
    "            black_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
    "            buffered = BytesIO()\n",
    "            black_image.save(buffered, format=\"JPEG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            black_face = {\n",
    "                \"frame_id\": -1,\n",
    "                \"bounding_box\": [0, 0, 0, 0],\n",
    "                \"face_emb\": np.zeros_like(cluster_faces[0][\"face_emb\"]).tolist(),\n",
    "                \"cluster_id\": -1,\n",
    "                \"extra_data\": {\"face_type\": \"other\", \"face_base64\": img_base64},\n",
    "            }\n",
    "            faces_list.append(black_face)\n",
    "\n",
    "    return faces_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_thinkings_with_ids(video_context, video_description):\n",
    "    input = video_context + [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": f\"video_description: {video_description}\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_generate_thinkings_with_ids,\n",
    "        },\n",
    "    ]\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = get_response_with_retry(model, messages)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_captions_and_thinkings_with_ids(\n",
    "    base64_video, base64_frames, base64_audio, faces_list, voices_list\n",
    "):\n",
    "    face_frames = []\n",
    "\n",
    "    print(f\"id num: {len(faces_list)}\")\n",
    "    # print(len(faces_list[0]))\n",
    "\n",
    "    # Iterate through faces directly\n",
    "    for char_id, faces in faces_list.items():\n",
    "        face = faces[0]\n",
    "        frame_id = face[\"frame_id\"]\n",
    "        frame_base64 = base64_frames[frame_id]\n",
    "\n",
    "        # Convert base64 to PIL Image\n",
    "        frame_bytes = base64.b64decode(frame_base64)\n",
    "        frame_img = Image.open(BytesIO(frame_bytes))\n",
    "        draw = ImageDraw.Draw(frame_img)\n",
    "\n",
    "        # Draw current face\n",
    "        bbox = face[\"bounding_box\"]\n",
    "        draw.rectangle(\n",
    "            [(bbox[0], bbox[1]), (bbox[2], bbox[3])], outline=(0, 255, 0), width=4\n",
    "        )\n",
    "\n",
    "        # Convert back to base64\n",
    "        buffered = BytesIO()\n",
    "        frame_img.save(buffered, format=\"JPEG\")\n",
    "        frame_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "        face_frames.append((f\"<char_{char_id}>:\", frame_base64))\n",
    "\n",
    "    # print(video_url)\n",
    "    print(len(base64_video))\n",
    "    video_context = [\n",
    "        {\n",
    "            \"type\": \"video_base64\",\n",
    "            \"content\": base64_video,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"images\",\n",
    "            \"content\": face_frames,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": json.dumps(voices_list),\n",
    "        },\n",
    "    ]\n",
    "    input = video_context + [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_generate_captions_with_ids,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    captions = get_response_with_retry(model, messages)\n",
    "\n",
    "    # Visualize face frames with IDs\n",
    "    num_faces = len(face_frames)\n",
    "    num_rows = (num_faces + 2) // 3  # Round up division to get number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(15, 5 * num_rows))\n",
    "    axes = axes.ravel()  # Flatten axes array for easier indexing\n",
    "\n",
    "    for i, face_frame in enumerate(face_frames):\n",
    "        # Convert base64 to image array\n",
    "        img_bytes = base64.b64decode(face_frame[1])\n",
    "        img_array = np.array(Image.open(BytesIO(img_bytes)))\n",
    "\n",
    "        axes[i].imshow(img_array)\n",
    "        axes[i].set_title(face_frame[0])\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(voices_list)\n",
    "\n",
    "    thinkings = generate_thinkings_with_ids(video_context, captions[0])\n",
    "\n",
    "    return captions[0], thinkings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_descriptions(video_graph, video_descriptions_string):\n",
    "    def string_to_list(s):\n",
    "        try:\n",
    "            # Remove ```json or ``` from start/end\n",
    "            s = s.strip(\"```json\").strip(\"```\")\n",
    "            result = ast.literal_eval(s)\n",
    "            if isinstance(result, list):\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"Input string is not a list\")\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Parsing error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_video_description(video_description):\n",
    "        # video_description is a string like this: <char_1> xxx <char_2> xxx\n",
    "        # extract all the elements wrapped by < and >\n",
    "        entities = []\n",
    "        current_entity = \"\"\n",
    "        in_entity = False\n",
    "\n",
    "        for char in video_description:\n",
    "            if char == \"<\":\n",
    "                in_entity = True\n",
    "                current_entity = \"\"\n",
    "            elif char == \">\":\n",
    "                in_entity = False\n",
    "                node_type, node_id = current_entity.split(\"_\")\n",
    "                # TODO: check node_id dtype\n",
    "                entities.append((node_type, node_id))\n",
    "            else:\n",
    "                if in_entity:\n",
    "                    current_entity += char\n",
    "        return entities\n",
    "\n",
    "    def update_video_graph(video_graph, descriptions):\n",
    "        for description in descriptions:\n",
    "            new_node_id = video_graph.add_text_node(description)\n",
    "            entities = parse_video_description(description)\n",
    "            for _, node_id in entities:\n",
    "                video_graph.add_edge(new_node_id, node_id)\n",
    "\n",
    "    descriptions = string_to_list(video_descriptions_string)\n",
    "    print(descriptions)\n",
    "    update_video_graph(video_graph, descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(params):\n",
    "    frames = params[0]\n",
    "    offset = params[1]\n",
    "    req = SingleGetFaceRequest(frames=frames, Base=Base())\n",
    "    resp = test_client.SingleGetFace(req)\n",
    "    faces = resp.faces\n",
    "    for face in faces:\n",
    "        face.frame_id += offset\n",
    "    return faces\n",
    "\n",
    "\n",
    "def process_faces(video_graph, base64_frames, batch_size):\n",
    "    def get_embeddings(base64_frames, batch_size):\n",
    "        num_batches = (len(base64_frames) + batch_size - 1) // batch_size\n",
    "        batched_frames = [\n",
    "            (base64_frames[i * batch_size : (i + 1) * batch_size], i * batch_size)\n",
    "            for i in range(num_batches)\n",
    "        ]\n",
    "\n",
    "        faces = []\n",
    "\n",
    "        # parallel process the batches\n",
    "        with ThreadPoolExecutor(max_workers=num_batches) as executor:\n",
    "            for batch_faces in tqdm(\n",
    "                executor.map(process_batch, batched_frames), total=num_batches\n",
    "            ):\n",
    "                faces.extend(batch_faces)\n",
    "\n",
    "        req = SingleClusterFaceRequest(faces=faces, Base=Base())\n",
    "        resp = test_client.SingleClusterFace(req)\n",
    "\n",
    "        faces = resp.faces\n",
    "\n",
    "        return faces\n",
    "\n",
    "    def establish_mapping(faces, key=\"cluster_id\"):\n",
    "        mapping = {}\n",
    "        if key in faces[0].keys():\n",
    "            for face in faces:\n",
    "                id = face[key]\n",
    "                if id not in mapping:\n",
    "                    mapping[id] = []\n",
    "                mapping[id].append(face)\n",
    "        else:\n",
    "            raise ValueError(f\"key {key} not found in faces\")\n",
    "        # sort the faces in each cluster by detection score and quality score\n",
    "        for id in mapping:\n",
    "            mapping[id] = sorted(\n",
    "                mapping[id],\n",
    "                key=lambda x: (\n",
    "                    float(x[\"extra_data\"][\"face_detection_score\"]),\n",
    "                    float(x[\"extra_data\"][\"face_quality_score\"]),\n",
    "                ),\n",
    "                reverse=True,\n",
    "            )\n",
    "        return mapping\n",
    "\n",
    "    def filter_score_based(faces):\n",
    "        dthresh = 0.85\n",
    "        qthresh = 22\n",
    "        max_faces = 3\n",
    "        filtered_faces = [\n",
    "            face\n",
    "            for face in faces\n",
    "            if float(face[\"extra_data\"][\"face_detection_score\"]) > dthresh\n",
    "            and float(face[\"extra_data\"][\"face_quality_score\"]) > qthresh\n",
    "        ]\n",
    "        return filtered_faces[:max_faces]\n",
    "\n",
    "    def update_videograph(video_graph, tempid2faces, filter=None):\n",
    "        faces_list = []\n",
    "        for tempid, faces in tempid2faces.items():\n",
    "            if tempid == -1:\n",
    "                continue\n",
    "            if filter:\n",
    "                filtered_faces = filter(faces)\n",
    "            else:\n",
    "                filtered_faces = faces\n",
    "            face_embs = [face[\"face_emb\"] for face in filtered_faces]\n",
    "            matched_nodes = video_graph.search_img_nodes(face_embs)\n",
    "            if len(matched_nodes) > 0:\n",
    "                matched_node = matched_nodes[0][0]\n",
    "                video_graph.add_embedding(matched_node, face_embs)\n",
    "                for face in faces:\n",
    "                    face[\"matched_node\"] = matched_node\n",
    "            else:\n",
    "                matched_node = video_graph.add_img_node(face_embs)\n",
    "                for face in faces:\n",
    "                    face[\"matched_node\"] = matched_node\n",
    "            faces_list.extend(filtered_faces)\n",
    "\n",
    "        return faces_list\n",
    "\n",
    "    faces = get_embeddings(base64_frames, batch_size)\n",
    "\n",
    "    faces_json = [\n",
    "        {\n",
    "            \"frame_id\": face.frame_id,\n",
    "            \"bounding_box\": face.bounding_box,\n",
    "            \"face_emb\": face.face_emb,\n",
    "            \"cluster_id\": face.cluster_id,\n",
    "            \"extra_data\": face.extra_data,\n",
    "        }\n",
    "        for face in faces\n",
    "    ]\n",
    "\n",
    "    tempid2faces = establish_mapping(faces_json, key=\"cluster_id\")\n",
    "\n",
    "    tagged_faces_json = update_videograph(\n",
    "        video_graph, tempid2faces, filter=filter_score_based\n",
    "    )\n",
    "\n",
    "    id2faces = establish_mapping(tagged_faces_json, key=\"matched_node\")\n",
    "\n",
    "    return id2faces\n",
    "\n",
    "\n",
    "def process_voices(video_graph, base64_audio):\n",
    "    print(get_audio_info_from_base64(base64_audio))\n",
    "\n",
    "    input = [\n",
    "        {\n",
    "            \"type\": \"audio\",\n",
    "            \"content\": base64_audio,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_audio_diarization,\n",
    "        },\n",
    "    ]\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = get_response_with_retry(model, messages)\n",
    "\n",
    "    asrs = validate_and_fix_json(response[0])\n",
    "\n",
    "    return asrs\n",
    "\n",
    "\n",
    "def process_segment(video_graph, base64_video, base64_frames, base64_audio, batch_size):\n",
    "\n",
    "    print(f\"processing {len(base64_frames)} frames...\")\n",
    "\n",
    "    id2faces = process_faces(video_graph, base64_frames, batch_size)\n",
    "    print(id2faces.keys())\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    id2voices = process_voices(video_graph, base64_audio)\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    captions, thinkings = generate_captions_and_thinkings_with_ids(\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        base64_audio,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "    )\n",
    "\n",
    "    process_descriptions(video_graph, captions)\n",
    "    process_descriptions(video_graph, thinkings)\n",
    "\n",
    "    print(\"Finish processing segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds, fps, segment_limit=None\n",
    "):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "\n",
    "    video_info = get_video_info(video_path)\n",
    "    print(video_info)\n",
    "\n",
    "    # Process each interval\n",
    "    count = 0\n",
    "    for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        print(f\"Loading {count}-th clip starting at {start_time} seconds...\")\n",
    "        base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "            video_path, start_time, interval_seconds, fps\n",
    "        )\n",
    "\n",
    "        # Process frames for this interval\n",
    "        if base64_frames:\n",
    "            print(\n",
    "                f\"Starting processing {count}-th clip starting at {start_time} seconds...\"\n",
    "            )\n",
    "            process_segment(\n",
    "                video_graph,\n",
    "                base64_video,\n",
    "                base64_frames,\n",
    "                base64_audio,\n",
    "                interval_seconds * fps // (CLUSTER_SIZE),\n",
    "            )\n",
    "\n",
    "        if segment_limit is not None:\n",
    "            if count >= segment_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomav01iso2mp41', 'encoder': 'Lavf59.27.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 429, 'fps': 23.976023976023978, 'codec_name': 'av1', 'profile': '(libdav1d)', 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.68, 'bitrate': 561, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'av1', 'video_profile': '(libdav1d)', 'video_size': [1280, 720], 'video_bitrate': 429, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 1744.68, 'video_n_frames': 41830}\n",
      "/usr/local/lib/python3.9/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fps': 23.976023976023978, 'frames': 41830, 'duration': 1744.68, 'path': '/mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4', 'name': '5 Poor People vs 1 Secret Millionaire.mp4', 'width': 1280, 'height': 720, 'codec': None, 'format': None, 'fourcc': None}\n",
      "====================\n",
      "Loading 1-th clip starting at 0.0 seconds...\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomav01iso2mp41', 'encoder': 'Lavf59.27.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 429, 'fps': 23.976023976023978, 'codec_name': 'av1', 'profile': '(libdav1d)', 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.68, 'bitrate': 561, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'av1', 'video_profile': '(libdav1d)', 'video_size': [1280, 720], 'video_bitrate': 429, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 1744.68, 'video_n_frames': 41830}\n",
      "/usr/local/lib/python3.9/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomav01iso2mp41', 'encoder': 'Lavf59.27.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 429, 'fps': 23.976023976023978, 'codec_name': 'av1', 'profile': '(libdav1d)', 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.68, 'bitrate': 561, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'av1', 'video_profile': '(libdav1d)', 'video_size': [1280, 720], 'video_bitrate': 429, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 1744.68, 'video_n_frames': 41830}\n",
      "/usr/local/lib/python3.9/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "Starting processing 1-th clip starting at 0.0 seconds...\n",
      "processing 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Finish processing faces\n",
      "{'duration_seconds': 60.0, 'channels': 2, 'frame_rate_hz': 44100, 'sample_width_bytes': 2}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m video_graph \u001b[39m=\u001b[39m VideoGraph()\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m streaming_process_video(\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     video_graph, video_path, interval_seconds\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m, fps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, segment_limit\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m base64_frames:\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting processing \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m-th clip starting at \u001b[39m\u001b[39m{\u001b[39;00mstart_time\u001b[39m}\u001b[39;00m\u001b[39m seconds...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     process_segment(\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         video_graph,\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m         base64_video,\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         base64_frames,\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m         base64_audio,\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         interval_seconds \u001b[39m*\u001b[39;49m fps \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m (CLUSTER_SIZE),\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mif\u001b[39;00m segment_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mif\u001b[39;00m count \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m segment_limit:\n",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=144'>145</a>\u001b[0m \u001b[39mprint\u001b[39m(id2faces\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinish processing faces\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m id2voices \u001b[39m=\u001b[39m process_voices(video_graph, base64_audio)\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=148'>149</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinish processing voices\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m captions, thinkings \u001b[39m=\u001b[39m generate_captions_and_thinkings_with_ids(\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m     base64_video,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m     base64_frames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=155'>156</a>\u001b[0m     id2voices,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m )\n",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m messages \u001b[39m=\u001b[39m generate_messages(\u001b[39minput\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgemini-1.5-pro-002\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m response \u001b[39m=\u001b[39m get_response_with_retry(model, messages)\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m asrs \u001b[39m=\u001b[39m validate_and_fix_json(response[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mreturn\u001b[39;00m asrs\n",
      "File \u001b[0;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/utils/chat_api.py:50\u001b[0m, in \u001b[0;36mget_response_with_retry\u001b[0;34m(model, messages)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_RETRIES):\n\u001b[1;32m     49\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m get_response(model, messages)\n\u001b[1;32m     51\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     52\u001b[0m         sleep(\u001b[39m30\u001b[39m)\n",
      "File \u001b[0;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/utils/chat_api.py:29\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(model, messages)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_response\u001b[39m(model, messages):\n\u001b[1;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get chat completion response from specified model.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m        tuple: (response content, total tokens used)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     response \u001b[39m=\u001b[39m client[model]\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     30\u001b[0m         model\u001b[39m=\u001b[39;49mmodel, messages\u001b[39m=\u001b[39;49mmessages, temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[39m# return answer and number of tokens\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent, response\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mtotal_tokens\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    915\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    916\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    917\u001b[0m             {\n\u001b[1;32m    918\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    919\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    920\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m: audio,\n\u001b[1;32m    921\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    922\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    923\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    924\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    925\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    926\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_completion_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_completion_tokens,\n\u001b[1;32m    927\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    928\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m    929\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodalities\u001b[39;49m\u001b[39m\"\u001b[39;49m: modalities,\n\u001b[1;32m    930\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    931\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[1;32m    932\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m: prediction,\n\u001b[1;32m    933\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    934\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mreasoning_effort\u001b[39;49m\u001b[39m\"\u001b[39;49m: reasoning_effort,\n\u001b[1;32m    935\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    936\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    937\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mservice_tier\u001b[39;49m\u001b[39m\"\u001b[39;49m: service_tier,\n\u001b[1;32m    938\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    939\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstore\u001b[39;49m\u001b[39m\"\u001b[39;49m: store,\n\u001b[1;32m    940\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    941\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m    942\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    943\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    944\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    945\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    946\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    947\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    948\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mweb_search_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: web_search_options,\n\u001b[1;32m    949\u001b[0m             },\n\u001b[1;32m    950\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    951\u001b[0m         ),\n\u001b[1;32m    952\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    953\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    954\u001b[0m         ),\n\u001b[1;32m    955\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    956\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    957\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    958\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    920\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    921\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    922\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    923\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    924\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m    925\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mSending HTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    956\u001b[0m         request,\n\u001b[1;32m    957\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    958\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1016\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/usr/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1102\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_graph = VideoGraph()\n",
    "video_path = \"/mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4\"\n",
    "\n",
    "streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds=60, fps=5, segment_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
