{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bytedtrace/__init__.py:108: UserWarning: [bytedtrace] global tracer is already initialized.\n",
      "  warnings.warn('[bytedtrace] global tracer is already initialized.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from videograph import VideoGraph\n",
    "from utils.general import *\n",
    "from utils.video_processing import *\n",
    "from utils.chat_api import *\n",
    "from prompts import *\n",
    "\n",
    "from face_processing import process_faces\n",
    "from voice_processing import process_voices\n",
    "from memory_processing import (\n",
    "    process_captions,\n",
    "    generate_captions_and_thinkings_with_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(video_graph, base64_video, base64_frames, base64_audio):\n",
    "\n",
    "    id2voices = process_voices(video_graph, base64_audio)\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    print(f\"processing {len(base64_frames)} frames...\")\n",
    "\n",
    "    id2faces = process_faces(video_graph, base64_frames)\n",
    "    print(id2faces.keys())\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    episodic_captions, semantic_captions = generate_captions_and_thinkings_with_ids(\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        base64_audio,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "    )\n",
    "\n",
    "    process_captions(video_graph, episodic_captions, type=\"episodic\")\n",
    "    process_captions(video_graph, semantic_captions, type=\"semantic\")\n",
    "\n",
    "    print(\"Finish processing segment\")\n",
    "\n",
    "\n",
    "def streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds, fps, segment_limit=None\n",
    "):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file or directory containing clips\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    if os.path.isfile(video_path):\n",
    "        # Process single video file\n",
    "        video_info = get_video_info(video_path)\n",
    "        print(video_info)\n",
    "\n",
    "        # Process each interval\n",
    "        count = 0\n",
    "        for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "            if start_time + interval_seconds > video_info[\"duration\"]:\n",
    "                break\n",
    "\n",
    "            print(\"=\" * 20)\n",
    "            count += 1\n",
    "\n",
    "            print(f\"Loading {count}-th clip starting at {start_time} seconds...\")\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                video_path, start_time, interval_seconds, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            # check dtype\n",
    "            # print(type(base64_video), type(base64_frames[0]), type(base64_audio))\n",
    "\n",
    "            # Process frames for this interval\n",
    "            if base64_frames:\n",
    "                print(\n",
    "                    f\"Starting processing {count}-th clip starting at {start_time} seconds...\"\n",
    "                )\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break\n",
    "\n",
    "    elif os.path.isdir(video_path):\n",
    "        # Process directory of numbered clips\n",
    "        files = os.listdir(video_path)\n",
    "        # Filter for video files and sort by numeric value in filename\n",
    "        video_files = [\n",
    "            f for f in files if any(f.endswith(ext) for ext in [\".mp4\", \".avi\", \".mov\"])\n",
    "        ]\n",
    "        video_files.sort(key=lambda x: int(\"\".join(filter(str.isdigit, x))))\n",
    "\n",
    "        for count, video_file in enumerate(video_files, 1):\n",
    "            print(\"=\" * 20)\n",
    "            full_path = os.path.join(video_path, video_file)\n",
    "            print(f\"Processing clip {count}: {full_path}\")\n",
    "\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                full_path, 0, interval_seconds, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            if base64_frames:\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Processing clip 1: data/videos/clipped/5 Poor People vs 1 Secret Millionaire/1.mp4\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 1044, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 129, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 30.0, 'bitrate': 1179, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1280, 720], 'video_bitrate': 1044, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 129, 'video_duration': 30.0, 'video_n_frames': 719}\n",
      "/usr/local/lib/python3.9/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i data/videos/clipped/5 Poor People vs 1 Secret Millionaire/1.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 1044, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 129, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 30.0, 'bitrate': 1179, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1280, 720], 'video_bitrate': 1044, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 129, 'video_duration': 30.0, 'video_n_frames': 719}\n",
      "/usr/local/lib/python3.9/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i data/videos/clipped/5 Poor People vs 1 Secret Millionaire/1.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "Diarizing audio 1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 12:02:38,390 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/multimodal/crawl/openai/deployments/gemini-1.5-pro-002/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-03-22 12:02:38,438 - root - ERROR - [laplace] matx_inference ex\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/laplace/client/rpc_func.py\", line 310, in __call__\n",
      "    rsp = self._rpc_client.matx_inference(req)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 344, in call\n",
      "    return self._compose_middlewares(ctx, fn)(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 613, in new_next\n",
      "    return middleware(ctx, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 62, in close_connection_middleware\n",
      "    return ctx.next(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 613, in new_next\n",
      "    return middleware(ctx, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/bytedtrace_middleware.py\", line 214, in __call__\n",
      "    resp = ctx.next(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 613, in new_next\n",
      "    return middleware(ctx, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/metrics_middleware.py\", line 107, in __call__\n",
      "    return ctx.next(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 613, in new_next\n",
      "    return middleware(ctx, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/base_compat_middleware/__init__.py\", line 102, in client_middleware\n",
      "    return ctx.next(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/euler/client.py\", line 613, in new_next\n",
      "    return middleware(ctx, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/laplace/client/base_client.py\", line 10, in check_base_resp_middleware\n",
      "    raise RPCError(rsp.BaseResp.StatusCode, rsp.BaseResp.StatusMessage)\n",
      "laplace.exceptions.RPCError: code: -1, message: Traceback (most recent call last):\n",
      "  File \"/laplace/python/euler_server.py\", line 99, in matx_inference\n",
      "    output = endpoint_handler(feed_dict)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 63, in __call__\n",
      "    completion = self.generate(wav.decode(\"utf-8\"))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 54, in generate\n",
      "    emb = self.get_embedding(wav_file)\n",
      "  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 48, in get_embedding\n",
      "    return compute_embedding(wav)\n",
      "  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 42, in compute_embedding\n",
      "    wav = load_wav(wav_file)\n",
      "  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 32, in load_wav\n",
      "    wav, fs = torchaudio.load(wav_file)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/utils.py\", line 205, in load\n",
      "    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile.py\", line 27, in load\n",
      "    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile_backend.py\", line 221, in load\n",
      "    with soundfile.SoundFile(filepath, \"r\") as file_:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 690, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 1265, in _open\n",
      "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
      "soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x7f803cdfaea0>: Format not recognised.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start_time': '00:00', 'end_time': '00:07', 'speaker': '<speaker_1>', 'asr': \"We got Danny, Herm, Aaron, and JC, and five people who say they're a millionaire, but only one of them is, and the other four are lying.\", 'duration': 7}, {'start_time': '00:07', 'end_time': '00:10', 'speaker': '<speaker_1>', 'asr': \"Let's just start by just appearances.\", 'duration': 3}, {'start_time': '00:11', 'end_time': '00:13', 'speaker': '<speaker_1>', 'asr': \"You're broke.\", 'duration': 2}, {'start_time': '00:14', 'end_time': '00:20', 'speaker': '<speaker_2>', 'asr': \"Nah, bro. That's not right. That's not right, bro.\", 'duration': 6}, {'start_time': '00:20', 'end_time': '00:28', 'speaker': '<speaker_1>', 'asr': \"'Cause you was in the guest of Black Presidents, and I think we had to pay him. Number five, your shoes are elite.\", 'duration': 8}, {'start_time': '00:28', 'end_time': '00:37', 'speaker': '<speaker_3>', 'asr': \"When a white man doesn't wear socks, that means very comfortable with\", 'duration': 9}]\n",
      "<class 'list'>\n",
      "<class 'bytes'>\n",
      "[b'AQACAIA+AAA=', b'UklGRkZMHQ==', b'AFdB', b'RWY=']\n"
     ]
    },
    {
     "ename": "RPCError",
     "evalue": "code: -1, message: Traceback (most recent call last):\n  File \"/laplace/python/euler_server.py\", line 99, in matx_inference\n    output = endpoint_handler(feed_dict)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 63, in __call__\n    completion = self.generate(wav.decode(\"utf-8\"))\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 54, in generate\n    emb = self.get_embedding(wav_file)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 48, in get_embedding\n    return compute_embedding(wav)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 42, in compute_embedding\n    wav = load_wav(wav_file)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 32, in load_wav\n    wav, fs = torchaudio.load(wav_file)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/utils.py\", line 205, in load\n    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile.py\", line 27, in load\n    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile_backend.py\", line 221, in load\n    with soundfile.SoundFile(filepath, \"r\") as file_:\n  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 690, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 1265, in _open\n    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\nsoundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x7f803cdfaea0>: Format not recognised.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRPCError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# video_path = \"/mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/videos/clipped/5 Poor People vs 1 Secret Millionaire\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m streaming_process_video(\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     video_graph, video_path, interval_seconds\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m, fps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, segment_limit\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m base64_video, base64_frames, base64_audio \u001b[39m=\u001b[39m process_video_clip(\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m     full_path, \u001b[39m0\u001b[39m, interval_seconds, fps\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mif\u001b[39;00m base64_frames:\n\u001b[0;32m---> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m     process_segment(\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m         video_graph,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m         base64_video,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m         base64_frames,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m         base64_audio,\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m segment_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m count \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m segment_limit:\n\u001b[1;32m    <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_segment\u001b[39m(video_graph, base64_video, base64_frames, base64_audio):\n\u001b[0;32m----> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     id2voices \u001b[39m=\u001b[39m process_voices(video_graph, base64_audio)\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinish processing voices\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/videonasi18n/longlin.kylin/mmagent/demo.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprocessing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(base64_frames)\u001b[39m}\u001b[39;00m\u001b[39m frames...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/voice_processing.py:231\u001b[0m, in \u001b[0;36mprocess_voices\u001b[0;34m(video_graph, base64_audio)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m _, audios \u001b[39min\u001b[39;00m tempid2audios\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    230\u001b[0m     audio_segments \u001b[39m=\u001b[39m [audio[\u001b[39m\"\u001b[39m\u001b[39maudio_segment\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m audio \u001b[39min\u001b[39;00m audios \u001b[39mif\u001b[39;00m audio[\u001b[39m\"\u001b[39m\u001b[39maudio_segment\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> 231\u001b[0m     embeddings \u001b[39m=\u001b[39m get_normed_audio_embeddings(audio_segments)\n\u001b[1;32m    232\u001b[0m     \u001b[39mfor\u001b[39;00m audio, embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(audios, embeddings):\n\u001b[1;32m    233\u001b[0m         audio[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m/mnt/bn/videonasi18n/longlin.kylin/mmagent/voice_processing.py:85\u001b[0m, in \u001b[0;36mget_normed_audio_embeddings\u001b[0;34m(base64_audios)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(base64_audios[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     84\u001b[0m \u001b[39mprint\u001b[39m(base64_audios)\n\u001b[0;32m---> 85\u001b[0m outputs \u001b[39m=\u001b[39m laplace\u001b[39m.\u001b[39;49mmatx_inference(\u001b[39m\"\u001b[39;49m\u001b[39maudio_embedding\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mwav\u001b[39;49m\u001b[39m\"\u001b[39;49m: base64_audios})\n\u001b[1;32m     86\u001b[0m \u001b[39mprint\u001b[39m(outputs)\n\u001b[1;32m     87\u001b[0m embeddings \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39moutput_bytes_lists[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/laplace/client/rpc_func.py:310\u001b[0m, in \u001b[0;36mmatx_inference.__call__\u001b[0;34m(self, model_name, input_lists, caller, ab_server, use_cache, update_cache, trace, input_dtypes)\u001b[0m\n\u001b[1;32m    308\u001b[0m     req\u001b[39m.\u001b[39mBase\u001b[39m.\u001b[39mCaller \u001b[39m=\u001b[39m caller\n\u001b[1;32m    309\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     rsp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rpc_client\u001b[39m.\u001b[39;49mmatx_inference(req)\n\u001b[1;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m rsp\n\u001b[1;32m    312\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:344\u001b[0m, in \u001b[0;36mClient.call\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instance:\n\u001b[1;32m    343\u001b[0m     ctx\u001b[39m.\u001b[39mlocal[\u001b[39m\"\u001b[39m\u001b[39mto_instance\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instance\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compose_middlewares(ctx, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:613\u001b[0m, in \u001b[0;36mClient._compose_middlewares.<locals>.f.<locals>.new_next\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_next\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    612\u001b[0m     ctx\u001b[39m.\u001b[39m_next \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m middleware(ctx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:62\u001b[0m, in \u001b[0;36mclose_connection_middleware\u001b[0;34m(ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose_connection_middleware\u001b[39m(ctx, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[39mreturn\u001b[39;00m ctx\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         client \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mlocal[\u001b[39m'\u001b[39m\u001b[39mthrift_client\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:613\u001b[0m, in \u001b[0;36mClient._compose_middlewares.<locals>.f.<locals>.new_next\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_next\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    612\u001b[0m     ctx\u001b[39m.\u001b[39m_next \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m middleware(ctx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/bytedtrace_middleware.py:214\u001b[0m, in \u001b[0;36mClientBytedTraceMiddleware.__call__\u001b[0;34m(self, ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msuccess\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     resp \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m     \u001b[39mreturn\u001b[39;00m resp\n\u001b[1;32m    216\u001b[0m \u001b[39mexcept\u001b[39;00m TTransportException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:613\u001b[0m, in \u001b[0;36mClient._compose_middlewares.<locals>.f.<locals>.new_next\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_next\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    612\u001b[0m     ctx\u001b[39m.\u001b[39m_next \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m middleware(ctx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/metrics_middleware.py:107\u001b[0m, in \u001b[0;36mClientMetricsMiddleware.__call__\u001b[0;34m(self, ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m error_code \u001b[39m=\u001b[39m euler\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUNKNOWN_ERROR_CODE\n\u001b[1;32m    106\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m ctx\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    108\u001b[0m \u001b[39mexcept\u001b[39;00m TTransportException:\n\u001b[1;32m    109\u001b[0m     ok \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:613\u001b[0m, in \u001b[0;36mClient._compose_middlewares.<locals>.f.<locals>.new_next\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_next\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    612\u001b[0m     ctx\u001b[39m.\u001b[39m_next \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m middleware(ctx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/base_compat_middleware/__init__.py:102\u001b[0m, in \u001b[0;36mclient_middleware\u001b[0;34m(ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m             req\u001b[39m.\u001b[39mBase\u001b[39m.\u001b[39mExtra[\u001b[39m'\u001b[39m\u001b[39muser_extra\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(user_extra, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39mBytesEncoder)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ctx\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/euler/client.py:613\u001b[0m, in \u001b[0;36mClient._compose_middlewares.<locals>.f.<locals>.new_next\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_next\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    612\u001b[0m     ctx\u001b[39m.\u001b[39m_next \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m middleware(ctx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/laplace/client/base_client.py:10\u001b[0m, in \u001b[0;36mcheck_base_resp_middleware\u001b[0;34m(ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m rsp \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mnext(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m rsp\u001b[39m.\u001b[39mBaseResp \u001b[39mand\u001b[39;00m rsp\u001b[39m.\u001b[39mBaseResp\u001b[39m.\u001b[39mStatusCode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mraise\u001b[39;00m RPCError(rsp\u001b[39m.\u001b[39mBaseResp\u001b[39m.\u001b[39mStatusCode, rsp\u001b[39m.\u001b[39mBaseResp\u001b[39m.\u001b[39mStatusMessage)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m rsp\n",
      "\u001b[0;31mRPCError\u001b[0m: code: -1, message: Traceback (most recent call last):\n  File \"/laplace/python/euler_server.py\", line 99, in matx_inference\n    output = endpoint_handler(feed_dict)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 63, in __call__\n    completion = self.generate(wav.decode(\"utf-8\"))\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 54, in generate\n    emb = self.get_embedding(wav_file)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 48, in get_embedding\n    return compute_embedding(wav)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 42, in compute_embedding\n    wav = load_wav(wav_file)\n  File \"/qs_service/model_compiled/audio_embedding/handler.py\", line 32, in load_wav\n    wav, fs = torchaudio.load(wav_file)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/utils.py\", line 205, in load\n    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile.py\", line 27, in load\n    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)\n  File \"/usr/local/lib/python3.9/dist-packages/torchaudio/_backend/soundfile_backend.py\", line 221, in load\n    with soundfile.SoundFile(filepath, \"r\") as file_:\n  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 690, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/usr/local/lib/python3.9/dist-packages/soundfile.py\", line 1265, in _open\n    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\nsoundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x7f803cdfaea0>: Format not recognised.\n"
     ]
    }
   ],
   "source": [
    "video_graph = VideoGraph()\n",
    "# video_path = \"/mnt/bn/videonasi18n/longlin.kylin/vlm-agent-benchmarking/data/videos/raw/720p/5 Poor People vs 1 Secret Millionaire.mp4\"\n",
    "video_path = \"data/videos/clipped/5 Poor People vs 1 Secret Millionaire\"\n",
    "\n",
    "streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds=60, fps=5, segment_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
