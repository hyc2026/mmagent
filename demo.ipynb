{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://bytedpypi.byted.org/simple\n",
      "Requirement already satisfied: bytedeuler in /usr/local/lib/python3.11/dist-packages (2.7.3)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (10.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Collecting pydub\n",
      "  Downloading http://bytedpypi.byted.org/packages/pydub/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
      "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
      "Requirement already satisfied: bytedtos in /usr/local/lib/python3.11/dist-packages (1.1.19)\n",
      "Requirement already satisfied: bytedance.context~=0.3 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.7.1)\n",
      "Requirement already satisfied: bytedance.versioncollect<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.2.0)\n",
      "Requirement already satisfied: bytedbackgrounds<1.0.0,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.0.6)\n",
      "Requirement already satisfied: byteddps<1.0.0,>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.1.2)\n",
      "Requirement already satisfied: bytedenv<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.6.4)\n",
      "Requirement already satisfied: bytedlogger<1.0.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.15.2)\n",
      "Requirement already satisfied: bytedlogid<1.0.0,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.2.1)\n",
      "Requirement already satisfied: bytedance.metrics<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.5.2)\n",
      "Requirement already satisfied: bytedservicediscovery~=0.17 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.18.0)\n",
      "Requirement already satisfied: bytedtrace<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.3.0)\n",
      "Requirement already satisfied: gevent<25.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (24.11.1)\n",
      "Requirement already satisfied: gunicorn<21,>=19 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (20.1.0)\n",
      "Requirement already satisfied: psutil<=6.0.0,>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (6.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (2.32.3)\n",
      "Requirement already satisfied: six<2.0.0,>=1.13.0 in /usr/lib/python3/dist-packages (from bytedeuler) (1.16.0)\n",
      "Requirement already satisfied: thriftpy2<1.0.0,>=0.4.20 in /usr/local/lib/python3.11/dist-packages (from bytedeuler) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from bytedtos) (1.7)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: msgpack<1.1.0,>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from bytedance.metrics<1.0.0,>=0.5.1->bytedeuler) (1.0.8)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from bytedance.versioncollect<1.0.0,>=0.0.1->bytedeuler) (1.26.20)\n",
      "Requirement already satisfied: schedule<2.0.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from bytedbackgrounds<1.0.0,>=0.0.2->bytedeuler) (1.2.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=1.0.0 in /usr/lib/python3/dist-packages (from byteddps<1.0.0,>=0.0.9->bytedeuler) (2.6.0)\n",
      "Requirement already satisfied: ipaddress<2.0.0,>=1.0.10 in /usr/local/lib/python3.11/dist-packages (from bytedenv<1.0.0,>=0.3.1->bytedeuler) (1.0.23)\n",
      "Requirement already satisfied: bytedtcc<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.4.5)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from bytedtrace<1.0.0,>=0.2.0->bytedeuler) (3.20.3)\n",
      "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent<25.0.0,>=1.0.1->bytedeuler) (5.0)\n",
      "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent<25.0.0,>=1.0.1->bytedeuler) (7.2)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from gevent<25.0.0,>=1.0.1->bytedeuler) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.11/dist-packages (from gunicorn<21,>=19->bytedeuler) (65.7.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.19.1->bytedeuler) (3.4.0)\n",
      "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from thriftpy2<1.0.0,>=0.4.20->bytedeuler) (3.0.12)\n",
      "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.11/dist-packages (from thriftpy2<1.0.0,>=0.4.20->bytedeuler) (3.11)\n",
      "Requirement already satisfied: python-etcd<1.0.0,>=0.4.5 in /usr/local/lib/python3.11/dist-packages (from bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.4.5)\n",
      "Requirement already satisfied: bytedztijwthelper<1.0.0,>=0.0.19 in /usr/local/lib/python3.11/dist-packages (from bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.0.23)\n",
      "Requirement already satisfied: bytedztispiffe<1.0.0,>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.0.16)\n",
      "Requirement already satisfied: Deprecated<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.2.18)\n",
      "Requirement already satisfied: bytedmemfd<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (0.2)\n",
      "Requirement already satisfied: dnspython>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from python-etcd<1.0.0,>=0.4.5->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (2.7.0)\n",
      "Requirement already satisfied: pyOpenSSL<27.0.0,>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (25.0.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.71.0)\n",
      "Requirement already satisfied: cryptography<50.0.0,>=3.4 in /usr/local/lib/python3.11/dist-packages (from bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (44.0.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated<2.0.0,>=1.1.0->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.17.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<50.0.0,>=3.4->bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<50.0.0,>=3.4->bytedztispiffe<1.0.0,>=0.0.4->bytedztijwthelper<1.0.0,>=0.0.19->bytedtcc<2.0.0,>=1.2.0->bytedtrace<1.0.0,>=0.2.0->bytedeuler) (2.22)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bytedeuler opencv-python-headless pillow matplotlib pydub scikit-learn tqdm openai moviepy bytedtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import euler\n",
    "\n",
    "euler.install_thrift_import_hook()\n",
    "\n",
    "from idl.base_thrift import *\n",
    "from idl.face_processing_thrift import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "from utils import *\n",
    "from prompts import *\n",
    "from videograph import VideoGraph\n",
    "from matplotlib import pyplot as plt\n",
    "import bytedtos\n",
    "import hashlib\n",
    "import string\n",
    "import random\n",
    "import tempfile\n",
    "import ast\n",
    "from pydub import AudioSegment\n",
    "from moviepy import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build client\n",
    "# test_client = euler.Client(FaceService, 'tcp://127.0.0.1:8910', timeout=300, transport='buffered')\n",
    "test_client = euler.Client(\n",
    "    FaceService,\n",
    "    \"sd://lab.agent.face_processing_test?idc=maliva&cluster=default\",\n",
    "    timeout=300,\n",
    "    transport=\"buffered\",\n",
    ")\n",
    "\n",
    "CLUSTER_SIZE = 100\n",
    "\n",
    "# os.environ['CONSUL_HTTP_HOST'] = \"10.54.129.29\"\n",
    "# os.environ['CONSUL_HTTP_PORT'] = 2280\n",
    "# PSM、Cluster、Idc、Accesskey 和 Bucket 可在 TOS 用户平台 > Bucket 详情 > 概览页中查找。具体查询方式详见方式二：通过 “psm+idc” 访问 TOS 桶 。\n",
    "\n",
    "server = \"va\"\n",
    "if server == \"cn\":\n",
    "    ak = \"YFPD6L54IEAAU421YMSG\"\n",
    "    bucket_name = \"vlm-agent\"\n",
    "    tos_psm = \"toutiao.tos.tosapi\"\n",
    "    tos_cluster = \"default\"\n",
    "    tos_idc = \"lf\"\n",
    "    base_url = \"https://tosv.byted.org/obj/vlm-agent/\"\n",
    "elif server == \"va\":\n",
    "    ak = \"BX2M82TQJ7UVTYXYO19Z\"\n",
    "    bucket_name = \"vlm-agent-benchmarking-us\"\n",
    "    tos_psm = \"toutiao.tos.tosapi\"\n",
    "    tos_cluster = \"default\"\n",
    "    tos_idc = \"maliva\"\n",
    "    base_url = \"https://tosv-va.tiktok-row.org/obj/vlm-agent-benchmarking-us/\"\n",
    "else:\n",
    "    raise ValueError(f\"Invalid server: {server}\")\n",
    "\n",
    "tos_client = bytedtos.Client(\n",
    "    bucket_name, ak, service=tos_psm, cluster=tos_cluster, idc=tos_idc\n",
    ")\n",
    "\n",
    "\n",
    "def get_hash_key(text):\n",
    "    md5_hash = hashlib.md5()\n",
    "    md5_hash.update(text.encode(\"utf-8\"))\n",
    "    hash_int = int.from_bytes(md5_hash.digest(), byteorder=\"big\")\n",
    "    return abs(hash_int) % (10**8)\n",
    "\n",
    "\n",
    "def generate_random_clip_name(length=10):\n",
    "    return \"\".join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "def upload_one_sample(file, do_upload=True):\n",
    "    try:\n",
    "        obj_key = generate_random_clip_name()\n",
    "        obj_url = base_url + obj_key\n",
    "        if do_upload:\n",
    "            content = open(file, \"rb\")\n",
    "            resp = tos_client.put_object(obj_key, content)\n",
    "            resp_code = int(resp.status_code)\n",
    "            if resp_code != 200:\n",
    "                print(f\"Upoload error code: {resp_code}\")\n",
    "                return -1, \"\"\n",
    "    except bytedtos.TosException as e:\n",
    "        print(\n",
    "            \"Upload failed. code: {}, request_id: {}, message: {}\".format(\n",
    "                e.code, e.request_id, e.msg\n",
    "            )\n",
    "        )\n",
    "        return -1, \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Other error: {e}\")\n",
    "        return -1, \"\"\n",
    "    return obj_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video_info = {}\n",
    "    video_info[\"fps\"] = video.fps\n",
    "    video_info[\"frames\"] = int(video.duration * video.fps)\n",
    "    video_info[\"duration\"] = video.duration\n",
    "    video_info[\"path\"] = video_path\n",
    "    video_info[\"name\"] = video_path.split(\"/\")[-1]\n",
    "    video_info[\"width\"] = video.size[0]\n",
    "    video_info[\"height\"] = video.size[1]\n",
    "    video_info[\"codec\"] = None  # moviepy doesn't expose codec info\n",
    "    video_info[\"format\"] = None  # moviepy doesn't expose format info\n",
    "    video_info[\"fourcc\"] = None  # moviepy doesn't expose fourcc info\n",
    "    video.close()\n",
    "    return video_info\n",
    "\n",
    "\n",
    "def extract_frames(video_path, start_time=None, interval=None, sample_fps=10):\n",
    "    video = VideoFileClip(video_path)\n",
    "\n",
    "    # if start_time and interval are not provided, sample the whole video at sample_fps\n",
    "    if start_time is None and interval is None:\n",
    "        start_time = 0\n",
    "        interval = video.duration\n",
    "\n",
    "    frames = []\n",
    "    frame_interval = 1.0 / sample_fps\n",
    "\n",
    "    # Extract frames at specified intervals\n",
    "    for t in np.arange(\n",
    "        start_time, min(start_time + interval, video.duration), frame_interval\n",
    "    ):\n",
    "        frame = video.get_frame(t)\n",
    "        # Convert frame to jpg and base64\n",
    "        _, buffer = cv2.imencode(\".jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "    video.close()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def get_video_codec(video_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    # Note: moviepy doesn't expose codec info directly\n",
    "    video.close()\n",
    "    return None\n",
    "\n",
    "\n",
    "def process_video_clip(video_path, start_time, interval, fps):\n",
    "    try:\n",
    "        base64_data = {}\n",
    "        video = VideoFileClip(video_path)\n",
    "\n",
    "        # Create subclip\n",
    "        clip = video.subclipped(start_time, start_time + interval)\n",
    "\n",
    "        # Create temporary files\n",
    "        temp_files = {\n",
    "            \"video\": tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\"),\n",
    "            \"audio\": tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\"),\n",
    "        }\n",
    "        temp_paths = {k: f.name for k, f in temp_files.items()}\n",
    "        for f in temp_files.values():\n",
    "            f.close()\n",
    "\n",
    "        # Write video without logging\n",
    "        clip.write_videofile(temp_paths[\"video\"], codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "\n",
    "        # Write audio without logging \n",
    "        clip.audio.write_audiofile(temp_paths[\"audio\"], codec=\"libmp3lame\", logger=None)\n",
    "\n",
    "        # Read files and convert to Base64\n",
    "        for key, path in temp_paths.items():\n",
    "            with open(path, \"rb\") as f:\n",
    "                base64_data[key] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "            os.remove(path)\n",
    "\n",
    "        # Extract frames\n",
    "        base64_data[\"frames\"] = extract_frames(video_path, start_time, interval, fps)\n",
    "\n",
    "        video.close()\n",
    "        clip.close()\n",
    "\n",
    "        return base64_data[\"video\"], base64_data[\"frames\"], base64_data[\"audio\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video clip: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_audio_info_from_base64(base64_string, format_hint=\"mp3\"):\n",
    "    try:\n",
    "        # decoding base64\n",
    "        audio_data = base64.b64decode(base64_string)\n",
    "        audio_io = BytesIO(audio_data)\n",
    "\n",
    "        if format_hint:\n",
    "            audio = AudioSegment.from_file(audio_io, format=format_hint)\n",
    "        else:\n",
    "            audio = AudioSegment.from_file(audio_io)\n",
    "\n",
    "        duration = len(audio) / 1000  # ms to s\n",
    "        channels = audio.channels\n",
    "        frame_rate = audio.frame_rate\n",
    "        sample_width = audio.sample_width\n",
    "\n",
    "        return {\n",
    "            \"duration_seconds\": duration,\n",
    "            \"channels\": channels,\n",
    "            \"frame_rate_hz\": frame_rate,\n",
    "            \"sample_width_bytes\": sample_width,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def get_video_info_from_base64(base64_string):\n",
    "    try:\n",
    "        video_data = base64.b64decode(base64_string)\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=True, suffix=\".mp4\") as temp_video:\n",
    "            temp_video.write(video_data)\n",
    "            temp_video.flush()\n",
    "\n",
    "            video = VideoFileClip(temp_video.name)\n",
    "            video_info = {\n",
    "                \"fps\": video.fps,\n",
    "                \"frames\": int(video.duration * video.fps),\n",
    "                \"duration\": video.duration,\n",
    "                \"path\": temp_video.name,\n",
    "                \"name\": os.path.basename(temp_video.name),\n",
    "                \"width\": video.size[0],\n",
    "                \"height\": video.size[1],\n",
    "                \"codec\": None,\n",
    "                \"format\": None,\n",
    "                \"fourcc\": None,\n",
    "            }\n",
    "            video.close()\n",
    "            return video_info\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the given faces are recognizable\n",
    "def batch_classify_faces(faces):\n",
    "    print(len(faces))\n",
    "    base64_faces = [face[\"extra_data\"][\"face_base64\"] for face in faces]\n",
    "    inputs = [\n",
    "        [\n",
    "            {\"type\": \"images\", \"content\": [base64_face]},\n",
    "            {\"type\": \"text\", \"content\": prompt_classify_recognizable_faces},\n",
    "        ]\n",
    "        for base64_face in base64_faces\n",
    "    ]\n",
    "    messages = [generate_messages(input) for input in inputs]\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = parallel_get_response(model, messages)\n",
    "    for i in range(len(response[0])):\n",
    "        faces[i][\"extra_data\"][\"recognizable\"] = int(response[0][i])\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_representative_faces_with_rules(faces):\n",
    "    \"\"\"Select the most representative face for each cluster based on face type, size and similarity.\n",
    "\n",
    "    Args:\n",
    "        faces (list): List of face dictionaries containing frame_id, bounding_box, face_emb,\n",
    "                     cluster_id and extra_data with face_type\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of cluster_id to the most representative face\n",
    "    \"\"\"\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    representative_faces = {}\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        # First try to find ortho faces\n",
    "        ortho_faces = []\n",
    "        side_faces = []\n",
    "        for f in cluster_faces:\n",
    "            if f[\"extra_data\"][\"face_type\"] == \"ortho\":\n",
    "                ortho_faces.append(f)\n",
    "            else:\n",
    "                side_faces.append(f)\n",
    "\n",
    "        if ortho_faces:\n",
    "            # For ortho faces, first select top 10% by size\n",
    "            areas = [\n",
    "                (\n",
    "                    f,\n",
    "                    (f[\"bounding_box\"][2] - f[\"bounding_box\"][0])\n",
    "                    * (f[\"bounding_box\"][3] - f[\"bounding_box\"][1]),\n",
    "                )\n",
    "                for f in ortho_faces\n",
    "            ]\n",
    "            areas.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_size_faces = [f[0] for f in areas[: max(1, int(len(areas) * 0.1))]]\n",
    "\n",
    "            # If only one face remains, use it directly\n",
    "            if len(top_size_faces) == 1:\n",
    "                best_face = top_size_faces[0]\n",
    "            else:\n",
    "                # Find the one with highest average similarity to all faces in cluster\n",
    "                max_avg_similarity = -1\n",
    "                best_face = None\n",
    "                cluster_embeddings = np.array(\n",
    "                    [face[\"face_emb\"] for face in cluster_faces]\n",
    "                )\n",
    "\n",
    "                for face in top_size_faces:\n",
    "                    similarities = np.dot(cluster_embeddings, face[\"face_emb\"])\n",
    "                    avg_similarity = (np.sum(similarities) - 1) / (\n",
    "                        len(cluster_faces) - 1\n",
    "                    )\n",
    "                    if avg_similarity > max_avg_similarity:\n",
    "                        max_avg_similarity = avg_similarity\n",
    "                        best_face = face\n",
    "\n",
    "        else:\n",
    "            # For side faces, first select top 20% by aspect ratio closest to 1\n",
    "            if side_faces:\n",
    "                areas = [\n",
    "                    (\n",
    "                        f,\n",
    "                        (f[\"bounding_box\"][2] - f[\"bounding_box\"][0])\n",
    "                        * (f[\"bounding_box\"][3] - f[\"bounding_box\"][1]),\n",
    "                    )\n",
    "                    for f in side_faces\n",
    "                ]\n",
    "                areas.sort(key=lambda x: x[1], reverse=True)\n",
    "                top_area_faces = [f[0] for f in areas[: max(1, int(len(areas) * 0.5))]]\n",
    "\n",
    "                # Then select top 20% by aspect ratio closest to 1\n",
    "                ratios = []\n",
    "                for face in top_area_faces:\n",
    "                    bbox = face[\"bounding_box\"]\n",
    "                    width = bbox[2] - bbox[0]\n",
    "                    height = bbox[3] - bbox[1]\n",
    "                    ratio = abs(width / height - 1.0)\n",
    "                    ratios.append((face, ratio))\n",
    "\n",
    "                ratios.sort(key=lambda x: x[1])  # Sort by ratio difference from 1\n",
    "                final_candidates = [\n",
    "                    f[0] for f in ratios[: max(1, int(len(ratios) * 0.2))]\n",
    "                ]\n",
    "\n",
    "                # If only one face remains, use it directly\n",
    "                if len(final_candidates) == 1:\n",
    "                    best_face = final_candidates[0]\n",
    "                else:\n",
    "                    # Find the one with highest average similarity to all faces in cluster\n",
    "                    max_avg_similarity = -1\n",
    "                    best_face = None\n",
    "                    cluster_embeddings = np.array(\n",
    "                        [face[\"face_emb\"] for face in cluster_faces]\n",
    "                    )\n",
    "\n",
    "                    for face in final_candidates:\n",
    "                        similarities = np.dot(cluster_embeddings, face[\"face_emb\"])\n",
    "                        avg_similarity = (np.sum(similarities) - 1) / (\n",
    "                            len(cluster_faces) - 1\n",
    "                        )\n",
    "                        if avg_similarity > max_avg_similarity:\n",
    "                            max_avg_similarity = avg_similarity\n",
    "                            best_face = face\n",
    "\n",
    "        representative_faces[cluster_id] = best_face\n",
    "\n",
    "    # return representative_faces\n",
    "\n",
    "    faces_list = []\n",
    "    for cluster_id, face in representative_faces.items():\n",
    "        faces_list.append(face)\n",
    "    return faces_list\n",
    "\n",
    "\n",
    "def select_representative_faces_with_scores(faces, max_faces=3):\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    faces_list = []\n",
    "    faces_per_cluster = {}\n",
    "    dthresh = 0.85\n",
    "    qthresh = 22\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        qualified_faces = [\n",
    "            face\n",
    "            for face in cluster_faces\n",
    "            if float(face[\"extra_data\"][\"face_detection_score\"]) > dthresh\n",
    "            and float(face[\"extra_data\"][\"face_quality_score\"]) > qthresh\n",
    "        ]\n",
    "        if qualified_faces:\n",
    "            # Sort faces by face_detection_score and face_quality_score\n",
    "            sorted_faces = sorted(\n",
    "                qualified_faces,\n",
    "                key=lambda x: (\n",
    "                    float(x[\"extra_data\"][\"face_detection_score\"]),\n",
    "                    float(x[\"extra_data\"][\"face_quality_score\"]),\n",
    "                ),\n",
    "                reverse=True,\n",
    "            )\n",
    "            # Select the face with the highest face_detection_score and face_quality_score\n",
    "            best_faces = sorted_faces[:max_faces]\n",
    "            faces_per_cluster[cluster_id] = best_faces\n",
    "            faces_list.append(best_faces)\n",
    "\n",
    "    return faces_list\n",
    "    # return faces_per_cluster\n",
    "\n",
    "\n",
    "def select_representative_faces_with_gpt(faces):\n",
    "    # Group faces by cluster\n",
    "    clusters = {}\n",
    "    for face in faces:\n",
    "        cluster_id = face[\"cluster_id\"]\n",
    "        if cluster_id == -1:  # Skip noise points\n",
    "            continue\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(face)\n",
    "\n",
    "    faces_list = []\n",
    "\n",
    "    # For each cluster, find the best representative face\n",
    "    for cluster_id, cluster_faces in clusters.items():\n",
    "        faces_base64 = [face[\"extra_data\"][\"face_base64\"] for face in cluster_faces]\n",
    "        print(f\"faces number: {len(faces_base64)}\")\n",
    "        # model = 'gemini-1.5-pro-002'\n",
    "        # input = [\n",
    "        #     {\n",
    "        #         \"type\": \"images\",\n",
    "        #         \"content\": faces_base64,\n",
    "        #     },\n",
    "        #     {\n",
    "        #         \"type\": \"text\",\n",
    "        #         \"content\": prompt_select_representative_faces,\n",
    "        #     }\n",
    "        # ]\n",
    "        model = \"gpt-4o-2024-11-20\"\n",
    "        input = [\n",
    "            {\n",
    "                \"type\": \"images\",\n",
    "                \"content\": faces_base64,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": prompt_select_representative_faces_forced,\n",
    "            },\n",
    "        ]\n",
    "        messages = generate_messages(input)\n",
    "\n",
    "        response = get_response_with_retry(model, messages)\n",
    "        try:\n",
    "            index = int(response[0])\n",
    "            if index >= 0:\n",
    "                print(f\"best face: {index}\")\n",
    "                faces_list.append(cluster_faces[index])\n",
    "            else:\n",
    "                print(f\"cannot find a good face\")\n",
    "                # insert a face with black base64\n",
    "                size = (100, 100)\n",
    "                black_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
    "                buffered = BytesIO()\n",
    "                black_image.save(buffered, format=\"JPEG\")\n",
    "                img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "                black_face = {\n",
    "                    \"frame_id\": -1,\n",
    "                    \"bounding_box\": [0, 0, 0, 0],\n",
    "                    \"face_emb\": np.zeros_like(cluster_faces[0][\"face_emb\"]).tolist(),\n",
    "                    \"cluster_id\": -1,\n",
    "                    \"extra_data\": {\"face_type\": \"other\", \"face_base64\": img_base64},\n",
    "                }\n",
    "                faces_list.append(black_face)\n",
    "        except:\n",
    "            print(f\"cannot find a good face\")\n",
    "            # insert a face with black base64\n",
    "            size = (100, 100)\n",
    "            black_image = Image.new(\"RGB\", size, (0, 0, 0))\n",
    "            buffered = BytesIO()\n",
    "            black_image.save(buffered, format=\"JPEG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            black_face = {\n",
    "                \"frame_id\": -1,\n",
    "                \"bounding_box\": [0, 0, 0, 0],\n",
    "                \"face_emb\": np.zeros_like(cluster_faces[0][\"face_emb\"]).tolist(),\n",
    "                \"cluster_id\": -1,\n",
    "                \"extra_data\": {\"face_type\": \"other\", \"face_base64\": img_base64},\n",
    "            }\n",
    "            faces_list.append(black_face)\n",
    "\n",
    "    return faces_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_thinkings_with_ids(video_context, video_description):\n",
    "    input = video_context + [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": f\"video_description: {video_description}\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_generate_thinkings_with_ids,\n",
    "        },\n",
    "    ]\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = get_response_with_retry(model, messages)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_captions_and_thinkings_with_ids(\n",
    "    base64_video, base64_frames, base64_audio, faces_list, voices_list\n",
    "):\n",
    "    face_frames = []\n",
    "\n",
    "    print(f\"id num: {len(faces_list)}\")\n",
    "    # print(len(faces_list[0]))\n",
    "\n",
    "    # Iterate through faces directly\n",
    "    for char_id, faces in faces_list.items():\n",
    "        face = faces[0]\n",
    "        frame_id = face[\"frame_id\"]\n",
    "        frame_base64 = base64_frames[frame_id]\n",
    "\n",
    "        # Convert base64 to PIL Image\n",
    "        frame_bytes = base64.b64decode(frame_base64)\n",
    "        frame_img = Image.open(BytesIO(frame_bytes))\n",
    "        draw = ImageDraw.Draw(frame_img)\n",
    "\n",
    "        # Draw current face\n",
    "        bbox = face[\"bounding_box\"]\n",
    "        draw.rectangle(\n",
    "            [(bbox[0], bbox[1]), (bbox[2], bbox[3])], outline=(0, 255, 0), width=4\n",
    "        )\n",
    "\n",
    "        # Convert back to base64\n",
    "        buffered = BytesIO()\n",
    "        frame_img.save(buffered, format=\"JPEG\")\n",
    "        frame_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "        face_frames.append((f\"<char_{char_id}>:\", frame_base64))\n",
    "\n",
    "    # print(video_url)\n",
    "    print(len(base64_video))\n",
    "    video_context = [\n",
    "        {\n",
    "            \"type\": \"video_base64\",\n",
    "            \"content\": base64_video,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"images\",\n",
    "            \"content\": face_frames,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": json.dumps(voices_list),\n",
    "        },\n",
    "    ]\n",
    "    input = video_context + [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_generate_captions_with_ids,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    captions = get_response_with_retry(model, messages)\n",
    "\n",
    "    # Visualize face frames with IDs\n",
    "    num_faces = len(face_frames)\n",
    "    num_rows = (num_faces + 2) // 3  # Round up division to get number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(15, 5 * num_rows))\n",
    "    axes = axes.ravel()  # Flatten axes array for easier indexing\n",
    "\n",
    "    for i, face_frame in enumerate(face_frames):\n",
    "        # Convert base64 to image array\n",
    "        img_bytes = base64.b64decode(face_frame[1])\n",
    "        img_array = np.array(Image.open(BytesIO(img_bytes)))\n",
    "\n",
    "        axes[i].imshow(img_array)\n",
    "        axes[i].set_title(face_frame[0])\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(voices_list)\n",
    "\n",
    "    thinkings = generate_thinkings_with_ids(video_context, captions[0])\n",
    "\n",
    "    return captions[0], thinkings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_descriptions(video_graph, video_descriptions_string):\n",
    "    def string_to_list(s):\n",
    "        try:\n",
    "            # Remove ```json or ``` from start/end\n",
    "            s = s.strip(\"```json\").strip(\"```\")\n",
    "            result = ast.literal_eval(s)\n",
    "            if isinstance(result, list):\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"Input string is not a list\")\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Parsing error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_video_description(video_description):\n",
    "        # video_description is a string like this: <char_1> xxx <char_2> xxx\n",
    "        # extract all the elements wrapped by < and >\n",
    "        entities = []\n",
    "        current_entity = \"\"\n",
    "        in_entity = False\n",
    "\n",
    "        for char in video_description:\n",
    "            if char == \"<\":\n",
    "                in_entity = True\n",
    "                current_entity = \"\"\n",
    "            elif char == \">\":\n",
    "                in_entity = False\n",
    "                node_type, node_id = current_entity.split(\"_\")\n",
    "                # TODO: check node_id dtype\n",
    "                entities.append((node_type, node_id))\n",
    "            else:\n",
    "                if in_entity:\n",
    "                    current_entity += char\n",
    "        return entities\n",
    "\n",
    "    def update_video_graph(video_graph, descriptions):\n",
    "        for description in descriptions:\n",
    "            new_node_id = video_graph.add_text_node(description)\n",
    "            entities = parse_video_description(description)\n",
    "            for _, node_id in entities:\n",
    "                video_graph.add_edge(new_node_id, node_id)\n",
    "\n",
    "    descriptions = string_to_list(video_descriptions_string)\n",
    "    print(descriptions)\n",
    "    update_video_graph(video_graph, descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(params):\n",
    "    frames = params[0]\n",
    "    offset = params[1]\n",
    "    req = SingleGetFaceRequest(frames=frames, Base=Base())\n",
    "    resp = test_client.SingleGetFace(req)\n",
    "    faces = resp.faces\n",
    "    for face in faces:\n",
    "        face.frame_id += offset\n",
    "    return faces\n",
    "\n",
    "\n",
    "def process_faces(video_graph, base64_frames, batch_size):\n",
    "    def get_embeddings(base64_frames, batch_size):\n",
    "        num_batches = (len(base64_frames) + batch_size - 1) // batch_size\n",
    "        batched_frames = [\n",
    "            (base64_frames[i * batch_size : (i + 1) * batch_size], i * batch_size)\n",
    "            for i in range(num_batches)\n",
    "        ]\n",
    "\n",
    "        faces = []\n",
    "\n",
    "        # parallel process the batches\n",
    "        with ThreadPoolExecutor(max_workers=num_batches) as executor:\n",
    "            for batch_faces in tqdm(\n",
    "                executor.map(process_batch, batched_frames), total=num_batches\n",
    "            ):\n",
    "                faces.extend(batch_faces)\n",
    "\n",
    "        req = SingleClusterFaceRequest(faces=faces, Base=Base())\n",
    "        resp = test_client.SingleClusterFace(req)\n",
    "\n",
    "        faces = resp.faces\n",
    "\n",
    "        return faces\n",
    "\n",
    "    def establish_mapping(faces, key=\"cluster_id\"):\n",
    "        mapping = {}\n",
    "        if key in faces[0].keys():\n",
    "            for face in faces:\n",
    "                id = face[key]\n",
    "                if id not in mapping:\n",
    "                    mapping[id] = []\n",
    "                mapping[id].append(face)\n",
    "        else:\n",
    "            raise ValueError(f\"key {key} not found in faces\")\n",
    "        # sort the faces in each cluster by detection score and quality score\n",
    "        for id in mapping:\n",
    "            mapping[id] = sorted(\n",
    "                mapping[id],\n",
    "                key=lambda x: (\n",
    "                    float(x[\"extra_data\"][\"face_detection_score\"]),\n",
    "                    float(x[\"extra_data\"][\"face_quality_score\"]),\n",
    "                ),\n",
    "                reverse=True,\n",
    "            )\n",
    "        return mapping\n",
    "\n",
    "    def filter_score_based(faces):\n",
    "        dthresh = 0.85\n",
    "        qthresh = 22\n",
    "        max_faces = 3\n",
    "        filtered_faces = [\n",
    "            face\n",
    "            for face in faces\n",
    "            if float(face[\"extra_data\"][\"face_detection_score\"]) > dthresh\n",
    "            and float(face[\"extra_data\"][\"face_quality_score\"]) > qthresh\n",
    "        ]\n",
    "        return filtered_faces[:max_faces]\n",
    "\n",
    "    def update_videograph(video_graph, tempid2faces, filter=None):\n",
    "        faces_list = []\n",
    "        for tempid, faces in tempid2faces.items():\n",
    "            if tempid == -1:\n",
    "                continue\n",
    "            if filter:\n",
    "                filtered_faces = filter(faces)\n",
    "            else:\n",
    "                filtered_faces = faces\n",
    "            face_embs = [face[\"face_emb\"] for face in filtered_faces]\n",
    "            matched_nodes = video_graph.search_img_nodes(face_embs)\n",
    "            if len(matched_nodes) > 0:\n",
    "                matched_node = matched_nodes[0][0]\n",
    "                video_graph.add_embedding(matched_node, face_embs)\n",
    "                for face in faces:\n",
    "                    face[\"matched_node\"] = matched_node\n",
    "            else:\n",
    "                matched_node = video_graph.add_img_node(face_embs)\n",
    "                for face in faces:\n",
    "                    face[\"matched_node\"] = matched_node\n",
    "            faces_list.extend(filtered_faces)\n",
    "\n",
    "        return faces_list\n",
    "\n",
    "    faces = get_embeddings(base64_frames, batch_size)\n",
    "\n",
    "    faces_json = [\n",
    "        {\n",
    "            \"frame_id\": face.frame_id,\n",
    "            \"bounding_box\": face.bounding_box,\n",
    "            \"face_emb\": face.face_emb,\n",
    "            \"cluster_id\": face.cluster_id,\n",
    "            \"extra_data\": face.extra_data,\n",
    "        }\n",
    "        for face in faces\n",
    "    ]\n",
    "\n",
    "    tempid2faces = establish_mapping(faces_json, key=\"cluster_id\")\n",
    "\n",
    "    tagged_faces_json = update_videograph(\n",
    "        video_graph, tempid2faces, filter=filter_score_based\n",
    "    )\n",
    "\n",
    "    id2faces = establish_mapping(tagged_faces_json, key=\"matched_node\")\n",
    "\n",
    "    return id2faces\n",
    "\n",
    "\n",
    "def process_voices(video_graph, base64_audio):\n",
    "    print(get_audio_info_from_base64(base64_audio))\n",
    "\n",
    "    input = [\n",
    "        {\n",
    "            \"type\": \"audio\",\n",
    "            \"content\": base64_audio,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"content\": prompt_audio_diarization,\n",
    "        },\n",
    "    ]\n",
    "    messages = generate_messages(input)\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    response = get_response_with_retry(model, messages)\n",
    "\n",
    "    asrs = validate_and_fix_json(response[0])\n",
    "\n",
    "    return asrs\n",
    "\n",
    "\n",
    "def process_segment(video_graph, base64_video, base64_frames, base64_audio, batch_size):\n",
    "\n",
    "    print(f\"processing {len(base64_frames)} frames...\")\n",
    "\n",
    "    id2faces = process_faces(video_graph, base64_frames, batch_size)\n",
    "    print(id2faces.keys())\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    id2voices = process_voices(video_graph, base64_audio)\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    captions, thinkings = generate_captions_and_thinkings_with_ids(\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        base64_audio,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "    )\n",
    "\n",
    "    process_descriptions(video_graph, captions)\n",
    "    process_descriptions(video_graph, thinkings)\n",
    "\n",
    "    print(\"Finish processing segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds, fps, segment_limit=None\n",
    "):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "\n",
    "    video_info = get_video_info(video_path)\n",
    "    print(video_info)\n",
    "\n",
    "    # Process each interval\n",
    "    count = 0\n",
    "    for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        print(f\"Loading {count}-th clip starting at {start_time} seconds...\")\n",
    "        base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "            video_path, start_time, interval_seconds, fps\n",
    "        )\n",
    "\n",
    "        # Process frames for this interval\n",
    "        if base64_frames:\n",
    "            print(\n",
    "                f\"Starting processing {count}-th clip starting at {start_time} seconds...\"\n",
    "            )\n",
    "            process_segment(\n",
    "                video_graph,\n",
    "                base64_video,\n",
    "                base64_frames,\n",
    "                base64_audio,\n",
    "                interval_seconds * fps // (CLUSTER_SIZE),\n",
    "            )\n",
    "\n",
    "        if segment_limit is not None:\n",
    "            if count >= segment_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2025-02-17T22:45:05.000000Z', 'encoder': 'Google'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 129, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.63, 'bitrate': 261, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 129, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 1744.63, 'video_n_frames': 41829}\n",
      "/usr/local/lib/python3.11/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'fps': 23.976023976023978, 'frames': 41829, 'duration': 1744.63, 'path': '/mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4', 'name': '5 Poor People vs 1 Secret Millionaire.mp4', 'width': 640, 'height': 360, 'codec': None, 'format': None, 'fourcc': None}\n",
      "====================\n",
      "Loading 1-th clip starting at 0.0 seconds...\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2025-02-17T22:45:05.000000Z', 'encoder': 'Google'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 129, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.63, 'bitrate': 261, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 129, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 1744.63, 'video_n_frames': 41829}\n",
      "/usr/local/lib/python3.11/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2025-02-17T22:45:05.000000Z', 'encoder': 'Google'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 129, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'creation_time': '2025-02-17T22:45:05.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/17/2025.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1744.63, 'bitrate': 261, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 129, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 1744.63, 'video_n_frames': 41829}\n",
      "/usr/local/lib/python3.11/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "Starting processing 1-th clip starting at 0.0 seconds...\n",
      "processing 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:09<00:25,  2.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mprocess_faces.<locals>.get_embeddings\u001b[39m\u001b[34m(base64_frames, batch_size)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=num_batches) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_faces\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_frames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_batches\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_faces\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:320\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m video_graph = VideoGraph()\n\u001b[32m      2\u001b[39m video_path = \u001b[33m\"\u001b[39m\u001b[33m/mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mstreaming_process_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mstreaming_process_video\u001b[39m\u001b[34m(video_graph, video_path, interval_seconds, fps, segment_limit)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base64_frames:\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     35\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-th clip starting at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mprocess_segment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvideo_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase64_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase64_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase64_audio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterval_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mCLUSTER_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m segment_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m count >= segment_limit:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 144\u001b[39m, in \u001b[36mprocess_segment\u001b[39m\u001b[34m(video_graph, base64_video, base64_frames, base64_audio, batch_size)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mprocess_segment\u001b[39m(video_graph, base64_video, base64_frames, base64_audio, batch_size):\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprocessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base64_frames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m frames...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     id2faces = \u001b[43mprocess_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase64_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mprint\u001b[39m(id2faces.keys())\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinish processing faces\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mprocess_faces\u001b[39m\u001b[34m(video_graph, base64_frames, batch_size)\u001b[39m\n\u001b[32m     90\u001b[39m         faces_list.extend(filtered_faces)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m faces_list\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m faces = \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m faces_json = [\n\u001b[32m     97\u001b[39m     {\n\u001b[32m     98\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mframe_id\u001b[39m\u001b[33m\"\u001b[39m: face.frame_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces\n\u001b[32m    105\u001b[39m ]\n\u001b[32m    107\u001b[39m tempid2faces = establish_mapping(faces_json, key=\u001b[33m\"\u001b[39m\u001b[33mcluster_id\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mprocess_faces.<locals>.get_embeddings\u001b[39m\u001b[34m(base64_frames, batch_size)\u001b[39m\n\u001b[32m     20\u001b[39m faces = []\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# parallel process the batches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_faces\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_frames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_batches\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_faces\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:1112\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:1132\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1133\u001b[39m         lock.release()\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "video_graph = VideoGraph()\n",
    "video_path = \"/mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/raw/360p/5 Poor People vs 1 Secret Millionaire.mp4\"\n",
    "\n",
    "streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds=60, fps=5, segment_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
