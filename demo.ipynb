{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bytedtrace/__init__.py:108: UserWarning: [bytedtrace] global tracer is already initialized.\n",
      "  warnings.warn('[bytedtrace] global tracer is already initialized.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from videograph import VideoGraph\n",
    "from utils.general import *\n",
    "from utils.video_processing import *\n",
    "from utils.chat_api import *\n",
    "from prompts import *\n",
    "\n",
    "from face_processing import process_faces\n",
    "from voice_processing import process_voices\n",
    "from memory_processing import (\n",
    "    process_captions,\n",
    "    generate_captions_and_thinkings_with_ids,\n",
    ")\n",
    "from retrieve import answer_with_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(video_graph, base64_video, base64_frames, base64_audio):\n",
    "\n",
    "    id2voices = process_voices(video_graph, base64_audio, base64_video)\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    print(f\"processing {len(base64_frames)} frames...\")\n",
    "\n",
    "    id2faces = process_faces(video_graph, base64_frames)\n",
    "    # print(id2faces.keys())\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    episodic_captions, semantic_captions = generate_captions_and_thinkings_with_ids(\n",
    "        video_graph,\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        base64_audio,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "    )\n",
    "\n",
    "    process_captions(video_graph, episodic_captions, type=\"episodic\")\n",
    "    process_captions(video_graph, semantic_captions, type=\"semantic\")\n",
    "\n",
    "    print(\"Finish processing segment\")\n",
    "\n",
    "\n",
    "def streaming_process_video(\n",
    "    video_graph, video_path, interval_seconds, fps, segment_limit=None\n",
    "):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file or directory containing clips\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "    if os.path.isfile(video_path):\n",
    "        # Process single video file\n",
    "        video_info = get_video_info(video_path)\n",
    "        print(video_info)\n",
    "\n",
    "        # Process each interval\n",
    "        count = 0\n",
    "        for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "            if start_time + interval_seconds > video_info[\"duration\"]:\n",
    "                break\n",
    "\n",
    "            print(\"=\" * 20)\n",
    "            count += 1\n",
    "\n",
    "            print(f\"Loading {count}-th clip starting at {start_time} seconds...\")\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                video_path, start_time, interval_seconds, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            # check dtype\n",
    "            # print(type(base64_video), type(base64_frames[0]), type(base64_audio))\n",
    "\n",
    "            # Process frames for this interval\n",
    "            if base64_frames:\n",
    "                print(\n",
    "                    f\"Starting processing {count}-th clip starting at {start_time} seconds...\"\n",
    "                )\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break\n",
    "\n",
    "    elif os.path.isdir(video_path):\n",
    "        # Process directory of numbered clips\n",
    "        files = os.listdir(video_path)\n",
    "        # Filter for video files and sort by numeric value in filename\n",
    "        video_files = [\n",
    "            f for f in files if any(f.endswith(ext) for ext in [\".mp4\", \".avi\", \".mov\"])\n",
    "        ]\n",
    "        video_files.sort(key=lambda x: int(\"\".join(filter(str.isdigit, x))))\n",
    "\n",
    "        for count, video_file in enumerate(video_files, 1):\n",
    "            print(\"=\" * 20)\n",
    "            full_path = os.path.join(video_path, video_file)\n",
    "            print(f\"Processing clip {count}: {full_path}\")\n",
    "\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                full_path, 0, None, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            if base64_frames:\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                )\n",
    "\n",
    "            if segment_limit is not None and count >= segment_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_config = json.load(open(\"configs/processing_config.json\"))\n",
    "memory_config = json.load(open(\"configs/memory_config.json\"))\n",
    "# video paths can be paths to directories or paths to mp4 files\n",
    "video_paths = processing_config[\"video_paths\"]\n",
    "\n",
    "for video_path in video_paths:\n",
    "\n",
    "    video_graph = VideoGraph(**memory_config)\n",
    "\n",
    "    streaming_process_video(\n",
    "        video_graph,\n",
    "        video_path,\n",
    "        processing_config[\"interval_seconds\"],\n",
    "        processing_config[\"fps\"],\n",
    "        processing_config[\"segment_limit\"],\n",
    "    )\n",
    "\n",
    "    save_dir = \"data/video_graphs\"\n",
    "    save_video_graph(\n",
    "        video_graph, video_path, save_dir, (processing_config, memory_config)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video graph from data/video_graphs/5-Poor-People-vs-1-Secret-Millionaire_60_5_10_10_20_0.3_0.6_0.75.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/212 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:42,879 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 1/212 [00:01<04:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:43,368 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 2/212 [00:01<02:39,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:45,078 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "  1%|▏         | 3/212 [00:03<04:09,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:45,833 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "  2%|▏         | 4/212 [00:04<03:32,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:46,453 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 49/212 [00:04<00:08, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:47,426 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 25%|██▍       | 52/212 [00:05<00:11, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:47,940 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 69/212 [00:06<00:08, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:48,574 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:49,091 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 72/212 [00:07<00:12, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:49,895 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 42%|████▏     | 90/212 [00:08<00:08, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:51,258 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▌    | 117/212 [00:09<00:05, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:51,851 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 57%|█████▋    | 120/212 [00:10<00:06, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:52,590 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      " 94%|█████████▍| 199/212 [00:10<00:00, 39.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equivalences 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:53,557 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 212/212 [00:11<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating queries 0 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:54,408 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries: ['Person wearing a black bomber jacket', 'Individual dressed in jeans and a black bomber jacket']\n",
      "yes\n",
      "face_6 character_7\n",
      "yes\n",
      "face_10 character_2\n",
      "yes\n",
      "face_11 character_6\n",
      "yes\n",
      "face_10 character_2\n",
      "yes\n",
      "face_10 character_2\n",
      "yes\n",
      "face_11 character_6\n",
      "yes\n",
      "face_10 character_2\n",
      "yes\n",
      "face_8 character_4\n",
      "yes\n",
      "face_7 character_3\n",
      "['<character_7> is wearing a blue denim jacket and a white beanie.', '<character_2> is wearing a black bomber jacket and jeans.', '<face_120> wears a camouflage jacket and an orange baseball cap.', '<character_6> is wearing a blue button-down shirt, a dark jacket and gray pants.', '<character_2> is wearing a black bomber jacket.', '<character_2> is wearing a black jacket and jeans.', '<character_6> is wearing a blue button-down shirt, a dark jacket, and gray pants.', '<character_2> is wearing a black bomber jacket and jeans.', '<character_4> wears a purple crop top, purple jacket, and dark pants.', '<character_3> is wearing a black hoodie.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 06:06:55,754 - httpx - INFO - HTTP Request: POST https://search-va.byteintl.net/gpt/openapi/online/v2/crawl/openai/deployments/gpt-4o-2024-11-20/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<character_2> is wearing a black bomber jacket and jeans.\n"
     ]
    }
   ],
   "source": [
    "video_graph_path = \"data/video_graphs/5-Poor-People-vs-1-Secret-Millionaire_60_5_10_10_20_0.3_0.6_0.75.pkl\"\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "# for text_node in video_graph.text_nodes:\n",
    "#     print(video_graph.nodes[text_node].metadata['contents'])\n",
    "# for nodes, weight in video_graph.edges.items():\n",
    "#     if weight > 1:\n",
    "#         if video_graph.nodes[nodes[0]].type in [\"episodic\", \"semantic\"]:\n",
    "#            print(video_graph.nodes[nodes[0]].metadata['contents'])\n",
    "#         else:\n",
    "#            print(video_graph.nodes[nodes[1]].metadata['contents'])\n",
    "#         print(weight)\n",
    "\n",
    "video_graph.text_matching_threshold = 0.20\n",
    "video_graph.refresh_equivalences()\n",
    "\n",
    "# question = 'What does Demar Randy wear?'\n",
    "question = \"Who is wearing a black bomber jacket and jeans?\"\n",
    "related_memories, answer = answer_with_retrieval(video_graph, question, topk=10)\n",
    "           \n",
    "# video_graph.summarize(logging=True)\n",
    "# save_dir = \"data/video_graphs\"\n",
    "# save_video_graph(\n",
    "#     video_graph, None, save_dir, None, file_name='5-Poor-People-vs-1-Secret-Millionaire_60_5_5_10_20_0.3_0.6_0.75_augmented.pkl'\n",
    "# )\n",
    "# video_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<voice_0> introduces four individuals named Denny, Herm, Aaron, and JC, seated at a table.']\n",
      "['<voice_0> mentions five other individuals claiming to be millionaires, with only one being truthful.']\n",
      "['<face_10> is wearing a black jacket and jeans.']\n",
      "['<face_4> is wearing a baseball jersey.']\n",
      "['<face_10> points at someone off-screen.']\n",
      "['<voice_2> accuses <face_10> of being broke.']\n",
      "['<face_5> laughs and points.']\n",
      "['<voice_2> says that he had to pay <face_10> because he was a guest on the Black President show.']\n",
      "['<face_9> wears sunglasses.']\n",
      "['<face_10> is not wearing socks with his loafers.']\n",
      "['Equivalence: <face_4>, <voice_0>']\n",
      "['Equivalence: <face_7>, <voice_2>']\n",
      "['Equivalence: <face_5>, <voice_1>']\n",
      "['<face_10> is perceived as wealthy due to his shoes.']\n",
      "['<face_10> not wearing socks is interpreted as a sign of comfort and confidence by <voice_2>.']\n",
      "['The video depicts a game show or competition to identify a millionaire among a group of individuals.']\n",
      "['<face_7> is wearing a black hoodie.']\n",
      "['<face_28> is wearing a blue Drexel University hoodie.']\n",
      "['<face_4> is wearing a baseball jersey.']\n",
      "['<face_6> is wearing a blue denim jacket and a white beanie.']\n",
      "['<face_5> is wearing a beige t-shirt with tattoos on his arms.']\n",
      "['<face_10> is wearing a black bomber jacket and jeans.']\n",
      "['<face_9> is wearing a white long-sleeved shirt and tan pants.']\n",
      "['<face_11> is wearing a blue button-down shirt, a dark jacket and gray pants.']\n",
      "['<voice_3> speaks about penny loafers.']\n",
      "['<face_4> gestures with his hands while speaking.']\n",
      "['<face_10> points at someone off screen.']\n",
      "[\"<voice_2> mentions that millionaires don't dress up.\"]\n",
      "['<voice_0> describes the clothing of the group of millionaires.']\n",
      "['<voice_3> claims <face_11> works at Gelsons.']\n",
      "['Equivalence: <face_7>, <voice_3>']\n",
      "['Equivalence: <face_10>, <voice_2>']\n",
      "['<face_10> is being assessed by the group at the table on whether he is a millionaire.']\n",
      "[\"The individuals at the table are analyzing <face_10>'s attire and demeanor to determine his wealth.\"]\n",
      "['The group suspects <face_11> is pretending to be wealthy.']\n",
      "['<face_9> is wearing a white long-sleeved shirt and tan pants.']\n",
      "['<face_11> is wearing a blue button-down shirt, a dark jacket, and gray pants.']\n",
      "['<face_10> is wearing a black bomber jacket and jeans.']\n",
      "['<voice_48> asks if <face_4> is gazing.']\n",
      "['<voice_49> clarifies that he meant something else.']\n",
      "['<voice_2> asks for the English word for not paying attention.']\n",
      "[\"<voice_3> compliments a person's appearance, and mentions sparkly clothing.\"]\n",
      "['<face_4> gestures with his hands while talking.']\n",
      "['<face_10> points at someone while speaking.']\n",
      "[\"<voice_0> asks for the participants' names and jobs.\"]\n",
      "['<voice_50> says his name is Damar Randy.']\n",
      "['Equivalence: <face_10>, <voice_50>']\n",
      "['<face_4> is playful and expressive in his communication style.']\n",
      "['<face_7>, <face_5>, and <face_28> appear more reserved or introverted.']\n",
      "['<face_10> may work in a creative field, given his name and the video context.']\n",
      "['<face_4> is a host or moderator of the show.']\n",
      "['<face_9> and <face_11> are likely guests on the show.']\n",
      "['<face_10> is wearing a black bomber jacket.']\n",
      "['<face_8> is wearing a purple blazer and a sparkly top.']\n",
      "['<face_9> is wearing a white long-sleeved shirt, khaki pants, and sunglasses.']\n",
      "['<voice_68> introduces herself as Tori K. and mentions that her family works in the oil business.']\n",
      "[\"<face_4> raises both his hands in response to <voice_68>'s introduction.\"]\n",
      "[\"<voice_69> repeats the phrase 'She said her family' several times.\"]\n",
      "['<face_4> points at someone while seated at a table.']\n",
      "[\"<face_7> puts his hand to his face in a gesture of surprise upon hearing <voice_68>'s introduction.\"]\n",
      "['<face_9> introduces himself as Labone James.']\n",
      "[\"<face_7> laughs and covers his mouth with his hand in response to hearing <face_9>'s name.\"]\n",
      "[\"<voice_48> expresses amusement at <face_9>'s name and jokes that it's fitting.\"]\n",
      "['Equivalence: <face_8>, <voice_68>']\n",
      "['Equivalence: <face_9>, <voice_71>']\n",
      "[\"<face_4> and the others at the table react with surprise and amusement to <voice_68>'s statement about her family's involvement in the oil business.\"]\n",
      "['<face_9> likely has a privileged background due to his name and the reactions of the others.']\n",
      "[\"<voice_48> finds <face_9>'s name humorous and makes a joke about it.\"]\n",
      "['<face_5> is wearing a baseball cap and a light-colored t-shirt.']\n",
      "['<face_5> laughs and covers his ears.']\n",
      "['<face_6> wears a knit cap.']\n",
      "['<face_6> laughs while looking down at the table.']\n",
      "['<face_4> wears a baseball jersey.']\n",
      "['<face_4> laughs with his head down on the table.']\n",
      "['<face_28> is wearing a Drexel University hoodie.']\n",
      "['<face_28> has his arms crossed and is looking at <face_4>.']\n",
      "['<face_7> wears a dark hoodie.']\n",
      "['<face_7> holds a water bottle in his right hand while looking at <face_4>.']\n",
      "['<voice_70> asks <face_9> what he does for a living.']\n",
      "['<face_9> says that he is a creative.']\n",
      "['<face_10> puts his head in his hands.']\n",
      "['<voice_69> speculates that <face_9> might be broke.']\n",
      "['<face_9> reveals that he works for OnlyFans.']\n",
      "['<face_7> expresses surprise with his mouth open.']\n",
      "['<voice_88> expresses surprise and wonders if <face_9> makes a lot of money.']\n",
      "['<voice_70> asks <face_11> for his name and occupation.']\n",
      "['<face_11> identifies himself as Stuart Thompson and a professor.']\n",
      "['<face_7> says \"Damn.\"']\n",
      "['Equivalence: <face_11>, <voice_89>']\n",
      "['Equivalence: <face_7>, <voice_70>']\n",
      "['<face_9> is comfortable publicly sharing that he works for OnlyFans.']\n",
      "[\"<face_7> and the others sitting at the table appear surprised by <face_9>'s occupation.\"]\n",
      "[\"<face_10> appears embarrassed or disappointed by <face_9>'s reveal.\"]\n",
      "[\"The people sitting at the table seem to believe that being a 'creative' is not a lucrative profession and that professors do not make millions of dollars.\"]\n",
      "[\"<face_6> laughs and puts his hand on <face_4>'s shoulder.\"]\n",
      "['<face_4> laughs and gestures with his hands.']\n",
      "['<face_5> laughs and looks down.']\n",
      "['<face_7> laughs and points at <face_28>.']\n",
      "['<face_28> holds his chin and smiles.']\n",
      "['<face_10> crosses his arms.']\n",
      "['<face_9> stands with his arms crossed and wearing sunglasses.']\n",
      "['<face_11> listens to <face_9>.']\n",
      "['<face_8> looks down.']\n",
      "['<face_120> wears a camouflage jacket and an orange baseball cap.']\n",
      "[\"<voice_116> says: 'Yeah, you got tenure. Pete, try and convince us. Yes!'\"]\n",
      "[\"<voice_117> says: 'Okay. That's a nice school. That's a nice school. That's an expensive school, too.'\"]\n",
      "[\"<voice_118> says: 'Okay, number five. What is your name, and what do you do for a living?'\"]\n",
      "[\"<voice_119> says: 'Uh, my name is J.F. Harris. I'm a stand-up comedian, but that's not how I made my money.'\"]\n",
      "[\"<voice_119> says: 'Oh! How did you make your money?'\"]\n",
      "['Equivalence: <face_9>, <voice_119>']\n",
      "['Equivalence: <face_6>, <voice_116>']\n",
      "['<face_9> is a comedian who made his money through Bitcoin.']\n",
      "['<face_6> is inquisitive and enjoys engaging in conversations.']\n",
      "['<face_4> appears to be easily amused and expressive.']\n",
      "['<face_28> seems thoughtful and observant.']\n",
      "['<face_11> teaches Spanish at UCLA and likely has a stable income.']\n",
      "['<face_5> sits at a table, wearing a white t-shirt with a baseball logo and a white baseball cap.']\n",
      "[\"<face_7> sits at the table in a black hoodie with a logo that begins with 'S' and ends with 'O'.\"]\n",
      "[\"<voice_119> speaks to the group, mentioning 'index funds'.\"]\n",
      "['<face_11> listens to the conversation while standing.']\n",
      "['<face_28> has a shaved head, wears glasses, and a Drexel University hoodie.']\n",
      "['<face_28> gestures with his hands while talking.']\n",
      "['<voice_48> mentions that Bitcoin has been performing poorly recently.']\n",
      "['<face_8> stands with her arms crossed in front of her torso.']\n",
      "['<face_8> wears a purple crop top, purple jacket, and dark pants.']\n",
      "['<voice_119> mentions having money in Vanguard.']\n",
      "['<face_4> speaks animatedly, gesturing with his hand.']\n",
      "['<face_6> looks surprised and listens to <face_4>.']\n",
      "['<voice_116> mentions having eight dollars in Vanguard.']\n",
      "['<voice_118> asks <face_8> how she made her money.']\n",
      "['<voice_68> responds that she makes music and that her family is in the oil business.']\n",
      "['<face_7> points at <face_8> while talking about her.']\n",
      "['Equivalence: <face_5>, <voice_119>']\n",
      "['Equivalence: <face_7>, <voice_48>']\n",
      "['Equivalence: <face_4>, <voice_116>']\n",
      "['Equivalence: <face_28>, <voice_3>']\n",
      "['<face_5> invests in Vanguard.']\n",
      "['<face_7> is concerned about the recent performance of Bitcoin.']\n",
      "['<face_28> appears knowledgeable about finance and investments.']\n",
      "['<face_8> is a musician and comes from a wealthy family involved in the oil business.']\n",
      "['<face_28> seems to tease <face_4> about his knowledge of Vanguard.']\n",
      "['<face_7>, <face_28>, and <face_4> are likely friends based on their casual interactions.']\n",
      "['<voice_70> asks <face_8> if she works a job or does music full-time.']\n",
      "['<face_8> responds that she does music and works in advertising.']\n",
      "['<voice_3> asks <face_8> if she makes her money or has a trust fund.']\n",
      "['<face_8> replies that she has a trust fund from her family but grew up wanting to be an entrepreneur.']\n",
      "['<face_8> says her family is from Texas but she moved to LA to do advertising and music.']\n",
      "[\"<face_4> says he doesn't believe <face_8>.\"]\n",
      "[\"<face_5> laughs at <face_4>'s comment.\"]\n",
      "['<face_28> listens to the conversation and appears thoughtful, touching his chin.']\n",
      "['<voice_3> says that kids with trust funds never work hard.']\n",
      "['Equivalence: <face_4>, <voice_70>']\n",
      "['<face_8> is likely financially privileged, as she mentions having a trust fund.']\n",
      "['<face_8> claims to be entrepreneurial and work in advertising and music.']\n",
      "[\"<face_4>, <face_28>, <face_5>, and <face_6> express skepticism about <face_8>'s claims, implying a possible comedic or judgmental context.\"]\n",
      "['<face_7> reinforces the stereotype of trust fund recipients not working hard.']\n",
      "['The group at the table seems to be interviewing or evaluating <face_8>.']\n",
      "['<face_8> says she does music and advertising.']\n",
      "['<face_8> says she has a trust fund.']\n",
      "[\"<face_4> says he doesn't believe <face_8> has a work ethic.\"]\n",
      "[\"<face_5> laughs in response to <face_4>'s comment.\"]\n",
      "['<face_28> listens to the conversation with his hand on his chin.']\n",
      "[\"<voice_3> says that kids with trust funds don't work.\"]\n",
      "['<face_4> points at <face_8> and appears to be talking about her.']\n",
      "[\"<voice_68> reacts strongly to <voice_70>'s question about her work.\"]\n",
      "['<face_4> reiterates his point that <face_8> works.']\n",
      "['Equivalence: <face_5>, <voice_0>.']\n",
      "['<face_8> is assertive and confident in her responses.']\n",
      "[\"<face_4> is skeptical of <face_8>'s claims about working.\"]\n",
      "['<voice_3> has a preconceived notion about people with trust funds.']\n",
      "['There is a potential conflict or tension between <face_4> and <face_8> due to differing perspectives on work ethic.']\n",
      "['<voice_0> asks the other commentators who they think is not a millionaire.']\n",
      "['<voice_198> states that the Spanish professor is definitely not a millionaire.']\n",
      "['<voice_198> says they do not see the Spanish professor making a million dollars from teaching.']\n",
      "['<voice_199> asks who the others think is the millionaire.']\n",
      "['<face_11> bows his head as the commentators try to guess who the millionaire is.']\n",
      "['<voice_200> asserts that only millionaires thrift clothes, while pointing at <face_11>.']\n",
      "['Equivalence: <face_5>, <voice_198>']\n",
      "['Equivalence: <face_4>, <voice_200>']\n",
      "['Equivalence: <face_11>, <voice_198>']\n",
      "['<face_11> is a Spanish professor.']\n",
      "['<face_4> believes <face_11> is not a millionaire because he thrifted his clothing.']\n"
     ]
    }
   ],
   "source": [
    "for text_node in video_graph.text_nodes:\n",
    "    print(video_graph.nodes[text_node].metadata['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from retrieve import retrieve_from_videograph\n",
    "# from videograph import VideoGraph\n",
    "# from utils.chat_api import (\n",
    "#     generate_messages,\n",
    "#     get_response_with_retry,\n",
    "#     parallel_get_embedding,\n",
    "# )\n",
    "# from utils.general import validate_and_fix_python_list\n",
    "# from prompts import prompt_memory_retrieval\n",
    "\n",
    "# MAX_RETRIES = 3\n",
    "\n",
    "\n",
    "# def generate_queries(question, existing_knowledge=None, query_num=1):\n",
    "#     input = [\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"content\": prompt_memory_retrieval.format(\n",
    "#                 question=question,\n",
    "#                 query_num=query_num,\n",
    "#                 existing_knowledge=existing_knowledge,\n",
    "#             ),\n",
    "#         }\n",
    "#     ]\n",
    "#     messages = generate_messages(input)\n",
    "#     model = \"gpt-4o-2024-11-20\"\n",
    "#     queries = None\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         print(f\"Generating queries {i} times\")\n",
    "#         queries = get_response_with_retry(model, messages)[0]\n",
    "#         queries = validate_and_fix_python_list(queries)\n",
    "#         if queries is not None:\n",
    "#             break\n",
    "#     if queries is None:\n",
    "#         raise Exception(\"Failed to generate queries\")\n",
    "#     return queries\n",
    "\n",
    "\n",
    "# def retrieve_from_videograph(videograph, question, topk=3):\n",
    "#     queries = generate_queries(question)\n",
    "#     print(f\"Queries: {queries}\")\n",
    "\n",
    "#     model = \"text-embedding-3-large\"\n",
    "#     query_embeddings = parallel_get_embedding(model, queries)[0]\n",
    "\n",
    "#     related_nodes = []\n",
    "\n",
    "#     for query_embedding in query_embeddings:\n",
    "#         nodes = videograph.search_text_nodes(query_embedding)\n",
    "#         related_nodes.extend(nodes)\n",
    "\n",
    "#     related_nodes = list(set(related_nodes))\n",
    "#     return related_nodes\n",
    "\n",
    "\n",
    "# question = \"Denny\"\n",
    "# retrieved_nodes = retrieve_from_videograph(video_graph, question)\n",
    "# print(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
