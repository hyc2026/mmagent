{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from videograph import VideoGraph\n",
    "from utils.general import *\n",
    "from utils.video_processing import *\n",
    "from utils.chat_api import *\n",
    "from prompts import *\n",
    "\n",
    "from face_processing import process_faces\n",
    "from voice_processing import process_voices\n",
    "from memory_processing import (\n",
    "    process_captions,\n",
    "    generate_captions_and_thinkings_with_ids,\n",
    ")\n",
    "from retrieve import answer_with_retrieval\n",
    "\n",
    "processing_config = json.load(open(\"configs/processing_config.json\"))\n",
    "memory_config = json.load(open(\"configs/memory_config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(\n",
    "    video_graph,\n",
    "    base64_video,\n",
    "    base64_frames,\n",
    "    base64_audio,\n",
    "    clip_id,\n",
    "    video_path,\n",
    "    preprocessing=False,\n",
    "):\n",
    "    save_path = os.path.join(\n",
    "        processing_config[\"intermediate_save_dir\"], generate_file_name(video_path)\n",
    "    )\n",
    "\n",
    "    id2voices = process_voices(\n",
    "        video_graph,\n",
    "        base64_audio,\n",
    "        base64_video,\n",
    "        save_path=os.path.join(save_path, f\"clip_{clip_id}_voices.json\"),\n",
    "        preprocessing=preprocessing,\n",
    "    )\n",
    "    print(\"Finish processing voices\")\n",
    "\n",
    "    id2faces = process_faces(\n",
    "        video_graph,\n",
    "        base64_frames,\n",
    "        save_path=os.path.join(save_path, f\"clip_{clip_id}_faces.json\"),\n",
    "        preprocessing=preprocessing,\n",
    "    )\n",
    "    print(\"Finish processing faces\")\n",
    "\n",
    "    if preprocessing:\n",
    "        print(\"Finish preprocessing segment\")\n",
    "        return\n",
    "\n",
    "    episodic_captions, semantic_captions = generate_captions_and_thinkings_with_ids(\n",
    "        video_graph,\n",
    "        base64_video,\n",
    "        base64_frames,\n",
    "        id2faces,\n",
    "        id2voices,\n",
    "        clip_id,\n",
    "    )\n",
    "\n",
    "    process_captions(video_graph, episodic_captions, clip_id, type=\"episodic\")\n",
    "    process_captions(video_graph, semantic_captions, clip_id, type=\"semantic\")\n",
    "\n",
    "    print(\"Finish processing segment\")\n",
    "\n",
    "\n",
    "def streaming_process_video(video_graph, video_path, preprocessing=False):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_graph (VideoGraph): Graph object to store video information\n",
    "        video_path (str): Path to the video file or directory containing clips\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None: Updates video_graph in place with processed segments\n",
    "    \"\"\"\n",
    "    interval_seconds = processing_config[\"interval_seconds\"]\n",
    "    fps = processing_config[\"fps\"]\n",
    "    segment_limit = processing_config[\"segment_limit\"]\n",
    "\n",
    "    if os.path.isfile(video_path):\n",
    "        # Process single video file\n",
    "        video_info = get_video_info(video_path)\n",
    "\n",
    "        # Process each interval\n",
    "        clip_id = 0\n",
    "        for start_time in tqdm(np.arange(0, video_info[\"duration\"], interval_seconds)):\n",
    "            if start_time + interval_seconds > video_info[\"duration\"]:\n",
    "                break\n",
    "\n",
    "            print(\"=\" * 20)\n",
    "\n",
    "            print(f\"Loading {clip_id}-th clip starting at {start_time} seconds...\")\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                video_path, start_time, interval_seconds, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            # Process frames for this interval\n",
    "            if base64_frames:\n",
    "                print(\n",
    "                    f\"Starting processing {clip_id}-th clip starting at {start_time} seconds...\"\n",
    "                )\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                    clip_id,\n",
    "                    video_path,\n",
    "                    preprocessing,\n",
    "                )\n",
    "\n",
    "            clip_id += 1\n",
    "\n",
    "            if segment_limit > 0 and clip_id >= segment_limit:\n",
    "                break\n",
    "\n",
    "    elif os.path.isdir(video_path):\n",
    "        # Process directory of numbered clips\n",
    "        files = os.listdir(video_path)\n",
    "        # Filter for video files and sort by numeric value in filename\n",
    "        video_files = [\n",
    "            f for f in files if any(f.endswith(ext) for ext in [\".mp4\", \".avi\", \".mov\"])\n",
    "        ]\n",
    "        video_files.sort(key=lambda x: int(\"\".join(filter(str.isdigit, x))))\n",
    "\n",
    "        for clip_id, video_file in enumerate(tqdm(video_files)):\n",
    "            if segment_limit > 0 and clip_id >= segment_limit:\n",
    "                break\n",
    "            print(\"=\" * 20)\n",
    "            full_path = os.path.join(video_path, video_file)\n",
    "            print(f\"Starting processing {clip_id}-th clip: {full_path}\")\n",
    "\n",
    "            base64_video, base64_frames, base64_audio = process_video_clip(\n",
    "                full_path, 0, None, fps, audio_format=\"wav\"\n",
    "            )\n",
    "\n",
    "            if base64_frames:\n",
    "                process_segment(\n",
    "                    video_graph,\n",
    "                    base64_video,\n",
    "                    base64_frames,\n",
    "                    base64_audio,\n",
    "                    clip_id,\n",
    "                    video_path,\n",
    "                    preprocessing,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video paths can be paths to directories or paths to mp4 files\n",
    "video_paths = processing_config[\"video_paths\"]\n",
    "\n",
    "for video_path in video_paths:\n",
    "\n",
    "    video_graph = VideoGraph(**memory_config)\n",
    "\n",
    "    streaming_process_video(video_graph, video_path)\n",
    "\n",
    "    video_graph.refresh_equivalences()\n",
    "\n",
    "    save_dir = processing_config[\"save_dir\"]\n",
    "    save_video_graph(\n",
    "        video_graph,\n",
    "        video_path,\n",
    "        save_dir,\n",
    "        (processing_config, memory_config),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph_path = \"data/mems/UPk8fzT4t8o_60_5_-1_10_20_0.3_0.6.pkl\"\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "# for text_node in video_graph.text_nodes:\n",
    "#     print(video_graph.nodes[text_node].metadata['contents'])\n",
    "# for nodes, weight in video_graph.edges.items():\n",
    "#     if weight > 1:\n",
    "#         if video_graph.nodes[nodes[0]].type in [\"episodic\", \"semantic\"]:\n",
    "#            print(video_graph.nodes[nodes[0]].metadata['contents'])\n",
    "#         else:\n",
    "#            print(video_graph.nodes[nodes[1]].metadata['contents'])\n",
    "#         print(weight)\n",
    "\n",
    "# video_graph.refresh_equivalences()\n",
    "\n",
    "# question = 'What does Demar Randy wear?'\n",
    "# question = \"Who has an OnlyFans acclip_id?\"\n",
    "question = \"How might the social development of children living in military families be affected?\"\n",
    "# question = \"What is the rule of the game?\"\n",
    "answer = answer_with_retrieval(\n",
    "    video_graph,\n",
    "    question,\n",
    "    query_num=processing_config[\"query_num\"],\n",
    "    topk=processing_config[\"topk\"],\n",
    "    mode=\"argmax\",\n",
    ")\n",
    "\n",
    "# video_graph.summarize(logging=True)\n",
    "# save_dir = \"data/video_graphs\"\n",
    "# save_video_graph(\n",
    "#     video_graph, None, save_dir, None, file_name='5-Poor-People-vs-1-Secret-Millionaire_60_5_5_10_20_0.3_0.6_0.75_augmented.pkl'\n",
    "# )\n",
    "# video_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chat_api import *\n",
    "from utils.general import plot_cosine_similarity_distribution\n",
    "\n",
    "video_graph_path = \"data/video_graphs/5-Poor-People-vs-1-Secret-Millionaire_60_5_5_10_20_0.3_0.6_0.75.pkl\"\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "\n",
    "graph_embeddings = []\n",
    "\n",
    "for id, node in video_graph.nodes.items():\n",
    "    if node.type in [\"episodic\", \"semantic\"]:\n",
    "        graph_embeddings.extend(node.embeddings)\n",
    "\n",
    "# texts = [\"Clothing style of Demar Randy\", \"<voice_44> introduces himself as Demar Randy.\"]\n",
    "texts = [\"<face_4> points at <face_9>.\"]\n",
    "embs = parallel_get_embedding(\"text-embedding-3-large\", texts)[0]\n",
    "\n",
    "plot_cosine_similarity_distribution(graph_embeddings, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph_path = (\n",
    "    \"data/mems/5-Poor-People-vs-1-Secret-Millionaire_60_5_-1_10_20_0.3_0.6.pkl\"\n",
    ")\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "\n",
    "print(len(video_graph.text_nodes))\n",
    "\n",
    "# for text_node in video_graph.text_nodes:\n",
    "#     print(video_graph.nodes[text_node].metadata[\"contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph_path = (\n",
    "    \"data/mems/5-Poor-People-vs-1-Secret-Millionaire_60_5_-1_10_20_0.3_0.6.pkl\"\n",
    ")\n",
    "video_graph = load_video_graph(video_graph_path)\n",
    "\n",
    "# for clip_id, text_nodes in video_graph.text_nodes_by_clip.items():\n",
    "#     print(f\"Clip {clip_id}:\")\n",
    "#     for text_node in text_nodes:\n",
    "#         print(video_graph.nodes[text_node].metadata[\"contents\"])\n",
    "\n",
    "video_graph.print_img_nodes(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from retrieve import retrieve_from_videograph\n",
    "# from videograph import VideoGraph\n",
    "# from utils.chat_api import (\n",
    "#     generate_messages,\n",
    "#     get_response_with_retry,\n",
    "#     parallel_get_embedding,\n",
    "# )\n",
    "# from utils.general import validate_and_fix_python_list\n",
    "# from prompts import prompt_memory_retrieval\n",
    "\n",
    "# MAX_RETRIES = 3\n",
    "\n",
    "\n",
    "# def generate_queries(question, existing_knowledge=None, query_num=1):\n",
    "#     input = [\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"content\": prompt_memory_retrieval.format(\n",
    "#                 question=question,\n",
    "#                 query_num=query_num,\n",
    "#                 existing_knowledge=existing_knowledge,\n",
    "#             ),\n",
    "#         }\n",
    "#     ]\n",
    "#     messages = generate_messages(input)\n",
    "#     model = \"gpt-4o-2024-11-20\"\n",
    "#     queries = None\n",
    "#     for i in range(MAX_RETRIES):\n",
    "#         print(f\"Generating queries {i} times\")\n",
    "#         queries = get_response_with_retry(model, messages)[0]\n",
    "#         queries = validate_and_fix_python_list(queries)\n",
    "#         if queries is not None:\n",
    "#             break\n",
    "#     if queries is None:\n",
    "#         raise Exception(\"Failed to generate queries\")\n",
    "#     return queries\n",
    "\n",
    "\n",
    "# def retrieve_from_videograph(videograph, question, topk=3):\n",
    "#     queries = generate_queries(question)\n",
    "#     print(f\"Queries: {queries}\")\n",
    "\n",
    "#     model = \"text-embedding-3-large\"\n",
    "#     query_embeddings = parallel_get_embedding(model, queries)[0]\n",
    "\n",
    "#     related_nodes = []\n",
    "\n",
    "#     for query_embedding in query_embeddings:\n",
    "#         nodes = videograph.search_text_nodes(query_embedding)\n",
    "#         related_nodes.extend(nodes)\n",
    "\n",
    "#     related_nodes = list(set(related_nodes))\n",
    "#     return related_nodes\n",
    "\n",
    "\n",
    "# question = \"Denny\"\n",
    "# retrieved_nodes = retrieve_from_videograph(video_graph, question)\n",
    "# print(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "9e153c75-6630-46b6-af1a-76d1a8277f1c",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/tce-face-extraction/demo.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
