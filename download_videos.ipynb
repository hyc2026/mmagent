{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDYzNzIwNTMsImlzcyI6ImxvbmdsaW4ua3lsaW5AYnl0ZWRhbmNlLmNvbSJ9.Ua-Nu4ZsVuUO_0SsOPdNo9uuMvIdrp0vVtQQaCuhHT0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "token_url = \"http://spiderverse-va.byteintl.net/openapi/token\"\n",
    "data = {\n",
    "    \"username\": \"longlin.kylin@bytedance.com\",\n",
    "    \"secret_key\": \"702bf6cbb65ad9c9e8c7c40f40d077463ede19359cd899c6d8ba0d89cb414f01\",\n",
    "}\n",
    "resp = requests.post(token_url, data)\n",
    "token = resp.json()[\"token\"]\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    if not url.startswith(\"https://www.youtube.com/\"):\n",
    "        return None\n",
    "    if \"&\" in url:\n",
    "        pruned_url = url.split(\"&\")[0]\n",
    "    else:\n",
    "        pruned_url = url\n",
    "    return pruned_url, pruned_url.split(\"watch?v=\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CZ_4: downloading 43 videos.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other error: 'NoneType' object is not iterable\n",
      "CZ_5: downloading 100 videos.\n",
      "Other error: 'NoneType' object is not iterable\n",
      "ZZ_6: downloading 100 videos.\n"
     ]
    }
   ],
   "source": [
    "from mmagent.utils.tos import list_all_objects\n",
    "\n",
    "spider_url = \"http://spiderverse-va.byteintl.net/openapi/submit/stream/seed\"\n",
    "headers = {\"token\": f\"{token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/raw/CZ_4_refined.json\",\n",
    "    \"data/annotations/raw/CZ_5_refined.json\",\n",
    "    \"data/annotations/raw/ZZ_6_refined.json\"\n",
    "]\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    all_data = []\n",
    "    # Get all existing files\n",
    "    downloaded_files = list_all_objects(target_dir)\n",
    "\n",
    "    for video in videos:\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        if video_id in downloaded_files:\n",
    "            continue\n",
    "        seed_data = {}\n",
    "        seed_data[\"source_data\"] = video\n",
    "        seed_data[\"__custom_args\"] = [\"-f\", \"bestvideo[height=720]+bestaudio\"]\n",
    "        seed_data[\"video_id\"] = video_id\n",
    "        seed_data[\"store_key\"] = video_id + \".mp4\"\n",
    "        seed_data[\"dir_name\"] = marker\n",
    "        seed_data[\"url\"] = pruned_url\n",
    "        runtime_vars = {\"key\": \"value\"}\n",
    "        data = {\n",
    "            \"seedSetId\": 1614,\n",
    "            \"seedId\": 12563,\n",
    "            \"data\": json.dumps(seed_data),\n",
    "            \"runtimeVars\": json.dumps(runtime_vars),\n",
    "        }\n",
    "        all_data.append(data)\n",
    "\n",
    "    if len(all_data) == 0:\n",
    "        print(\"All data downloaded.\")\n",
    "        break\n",
    "\n",
    "    print(f\"{marker}: downloading {len(all_data)} videos.\")\n",
    "\n",
    "    qps = 5\n",
    "    import time\n",
    "\n",
    "    # resp = requests.post(spider_url, json=all_data[0], headers=headers)\n",
    "    # print(resp.json())\n",
    "\n",
    "    for i in range(0, len(all_data), qps):\n",
    "        batch = all_data[i : i + qps]\n",
    "        for data in batch:\n",
    "            resp = requests.post(spider_url, json=data, headers=headers)\n",
    "        if i + qps < len(all_data):  # Don't sleep after the last batch\n",
    "            time.sleep(1)  # Sleep 1 second between batches to maintain QPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:00<00:00, 121.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 53.06it/s]\n",
      "100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.tos import list_all_objects, download_one_sample\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/raw/CZ_3_refined.json\",\n",
    "    \"data/annotations/raw/CZ_4_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    # Get all existing files\n",
    "    downloaded_files = list_all_objects(target_dir)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        if not os.path.exists(save_file) and video_id in downloaded_files:\n",
    "            download_one_sample(save_file, target_dir + video_id + \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data downloaded.\n",
      "All data downloaded.\n"
     ]
    }
   ],
   "source": [
    "from utils.tos import list_all_objects\n",
    "import os\n",
    "\n",
    "spider_url = \"http://spiderverse-va.byteintl.net/openapi/submit/stream/seed\"\n",
    "headers = {\"token\": f\"{token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/ZZ_4_refined.json\",\n",
    "    \"data/annotations/ZZ_5_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "\n",
    "video_to_be_downloaded = {}\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    url_to_be_downloaded = []\n",
    "    # Get all existing files\n",
    "    downloaded_files = list_all_objects(target_dir)\n",
    "\n",
    "    for video in videos:\n",
    "        url = video[\"video_url\"]\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        # if video_id in downloaded_files:\n",
    "        #     continue\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        if os.path.exists(save_file):\n",
    "            continue\n",
    "        url_to_be_downloaded.append(pruned_url)\n",
    "\n",
    "    if len(url_to_be_downloaded) == 0:\n",
    "        print(\"All data downloaded.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"{marker} has {len(url_to_be_downloaded)} videos to be downloaded: {url_to_be_downloaded}\"\n",
    "        )\n",
    "\n",
    "    video_to_be_downloaded[marker] = url_to_be_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.96it/s]\n",
      "100%|██████████| 100/100 [01:26<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.tos import list_all_objects, upload_one_sample\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/ZZ_4_refined.json\",\n",
    "    \"data/annotations/ZZ_5_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "local_videos = os.listdir(\n",
    "    \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos/supp_videos\"\n",
    ")\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    # Get all existing files\n",
    "    downloaded_files = list_all_objects(target_dir)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        video[\"path\"] = save_file\n",
    "        if not os.path.exists(save_file):\n",
    "            # Check if video exists locally first\n",
    "            local_match = [f for f in local_videos if f.startswith(video_id)]\n",
    "            if local_match:\n",
    "                # Copy from local file to save location\n",
    "                local_file = os.path.join(\n",
    "                    \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos/supp_videos\",\n",
    "                    local_match[0],\n",
    "                )\n",
    "                file_name = os.path.basename(local_file)\n",
    "                shutil.copy(local_file, \"data/temp\")\n",
    "                upload_one_sample(\n",
    "                    os.path.join(\"data/temp\", file_name),\n",
    "                    obj_key=target_dir + video_id + \".mp4\",\n",
    "                )\n",
    "                os.remove(os.path.join(\"data/temp\", file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 0, 'message': 'request success'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://spiderverse-va.byteintl.net/openapi/submit/stream/seed\"\n",
    "headers = {\"token\": f\"{token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "seed_data = {\n",
    "    # 这个字段我放了你们的数据\n",
    "    \"source_data\": {\n",
    "        \"video_id\": \"CZ_1\",\n",
    "        \"video_url\": \"https://www.youtube.com/watch?v=PnvZZwlN2yk\",\n",
    "        \"video_duration\": \"29:04\",\n",
    "        \"video_type\": \"综艺 - 游戏\",\n",
    "        \"qa_list\": [\n",
    "            {\n",
    "                \"question\": \"Is Stewart Thompson a person who pursues a high-quality life?\",\n",
    "                \"answer\": \"Yes.\",\n",
    "                \"question_type\": \"多线索推理,人物属性建模\",\n",
    "                \"knowledge\": \"\",\n",
    "                \"reasoning\": \"从Stewart讲述自己旅行方式倾向于商务舱可以判断。\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    # 这里必须有，\n",
    "    \"__custom_args\": [\n",
    "        # 必须\n",
    "        \"-f\",\n",
    "        # format的筛选，你们自己确定\n",
    "        \"bestvideo[height=720]+bestaudio\",\n",
    "    ],\n",
    "    # ytb的视频id\n",
    "    \"video_id\": \"PnvZZwlN2yk\",\n",
    "    # 存储的文件名\n",
    "    \"store_key\": \"PnvZZwlN2yk.mp4\",\n",
    "    # 存储的文件夹\n",
    "    \"dir_name\": \"test_file\",\n",
    "    # ytb视频的链接，格式固定\n",
    "    \"url\": \"https://www.youtube.com/watch?v=PnvZZwlN2yk\",\n",
    "}\n",
    "\n",
    "runtime_vars = {\"key\": \"value\"}\n",
    "data = {\n",
    "    \"seedSetId\": 1614,\n",
    "    \"seedId\": 124,\n",
    "    \"data\": json.dumps(seed_data),\n",
    "    \"runtimeVars\": json.dumps(runtime_vars),\n",
    "}\n",
    "\n",
    "resp = requests.post(url, json=data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tos import download_one_sample\n",
    "\n",
    "download_one_sample(\"data/videos/raw/test/test1.mp4\", \"test_file/Ahrvn7IVgHk.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from youtube\n",
    "import yt_dlp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from utils.tos import list_all_objects\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/CZ_2_refined.json\",\n",
    "    \"data/annotations/CZ_3_refined.json\",\n",
    "    \"data/annotations/ZZ_4_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    # Get all existing files\n",
    "    downloaded_files = list_all_objects(target_dir)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        if not os.path.exists(save_file):\n",
    "            options = {\n",
    "                \"format\": f\"bestvideo[height=720]+bestaudio\",\n",
    "                \"outtmpl\": save_file,\n",
    "                \"quiet\": True,\n",
    "                \"cookiefile\": \"cookies/www.youtube.com_cookies.txt\",  # Path to your cookies.txt\n",
    "            }\n",
    "            with yt_dlp.YoutubeDL(options) as ydl:\n",
    "                try:\n",
    "                    # Update output template to use the specified path\n",
    "                    ydl.download([pruned_url])\n",
    "                    print(f\"Successfully downloaded video to {save_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading {pruned_url}: {str(e)}\")\n",
    "            video[\"path\"] = save_file\n",
    "\n",
    "    with open(annotations_path, \"w\") as f:\n",
    "        json.dump(videos, f)\n",
    "\n",
    "\n",
    "# with open(\"data/annotations/video_list_CZ.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# for video in data:\n",
    "#     url = video[\"video_url\"]\n",
    "#     pruned_url, video_id = parse_url(url)\n",
    "#     if pruned_url is None:\n",
    "#         video[\"path\"] = None\n",
    "#     else:\n",
    "#         video[\"path\"] = f\"{destination_folder}{video_id}.mp4\"\n",
    "#         video[\"video_url\"] = pruned_url\n",
    "\n",
    "# with open(\"data/annotations/video_list_CZ_modified.json\", \"w\") as f:\n",
    "#     json.dump(data, f, indent=4)\n",
    "\n",
    "# # 视频链接\n",
    "# urls = [\n",
    "#     \"https://www.youtube.com/watch?v=PnvZZwlN2yk&ab_channel=KevinLangue\",\n",
    "# ]\n",
    "\n",
    "# # 配置下载选项\n",
    "# # options = {\n",
    "# #     # \"format\": f\"bestvideo[height={resolution}]+bestaudio/best\",\n",
    "# #     \"format\": f\"bestvideo[ext=mp4][vcodec=h264][height={resolution}]+bestaudio[ext=m4a]/best[ext=mp4]\",\n",
    "# #     \"merge_output_format\": \"mp4\",  # 确保最终输出为 MP4\n",
    "# #     # \"outtmpl\": destination_folder + \"%(title)s.%(ext)s\",\n",
    "# #     \"postprocessors\": [{\"key\": \"FFmpegVideoConvertor\", \"preferedformat\": \"mp4\"}],\n",
    "# #     # \"quiet\": True,\n",
    "# # }\n",
    "\n",
    "# # 创建下载器对象并下载\n",
    "# count = 0\n",
    "\n",
    "# for video in tqdm(data):\n",
    "#     if video[\"path\"] is not None:\n",
    "#         options = {\n",
    "#             \"format\": f\"bestvideo[height={resolution}]+bestaudio\",\n",
    "#             \"outtmpl\": video[\"path\"],\n",
    "#             \"quiet\": True,\n",
    "#         }\n",
    "#         with yt_dlp.YoutubeDL(options) as ydl:\n",
    "#             try:\n",
    "#                 # Update output template to use the specified path\n",
    "#                 ydl.download([video[\"video_url\"]])\n",
    "#                 print(f\"Successfully downloaded video to {video['path']}\")\n",
    "#                 count += 1\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error downloading {video['video_url']}: {str(e)}\")\n",
    "\n",
    "# print(f\"Total downloaded videos: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 398.29it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 437.04it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 387.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 358.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/CZ_1_refined.json\",\n",
    "    \"data/annotations/ZZ_1_refined.json\",\n",
    "    \"data/annotations/ZZ_2_refined.json\",\n",
    "    \"data/annotations/ZZ_3_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "\n",
    "videos_to_be_downloaded = {}\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        if not os.path.exists(save_file):\n",
    "            if marker not in videos_to_be_downloaded:\n",
    "                videos_to_be_downloaded[marker] = []\n",
    "            videos_to_be_downloaded[marker].append(pruned_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=aptFRdzrVXk', 'https://www.youtube.com/watch?v=PF4XAuZEMok', 'https://www.youtube.com/watch?v=3Z_EZVJLKeI', 'https://www.youtube.com/watch?v=8FpPSMIB4uA', 'https://www.youtube.com/watch?v=PIxe19xS_18', 'https://www.youtube.com/watch?v=8TlrXc3TYgs', 'https://www.youtube.com/watch?v=4RcThoRG46c', 'https://www.youtube.com/watch?v=W6NpZsvzkDY', 'https://www.youtube.com/watch?v=nicMudN877M', 'https://www.youtube.com/watch?v=3ghDBAeKKbI', 'https://www.youtube.com/watch?v=xi6r3hZe5Tg']\n"
     ]
    }
   ],
   "source": [
    "print(videos_to_be_downloaded[\"ZZ_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils.video_processing import get_video_info\n",
    "\n",
    "annotations_paths = [\n",
    "    \"data/annotations/CZ_1_refined.json\",\n",
    "    \"data/annotations/ZZ_1_refined.json\",\n",
    "    \"data/annotations/ZZ_2_refined.json\",\n",
    "    \"data/annotations/ZZ_3_refined.json\",\n",
    "]\n",
    "base_save_dir = \"/mnt/hdfs/foundation/longlin.kylin/mmagent/data/raw_videos\"\n",
    "processing_config = json.load(open(\"configs/processing_config.json\", \"r\"))\n",
    "log_dir = processing_config[\"log_dir\"]\n",
    "\n",
    "videos_to_be_downloaded = {}\n",
    "\n",
    "for annotations_path in annotations_paths:\n",
    "    marker = annotations_path.split(\"/\")[-1].split(\".\")[0].strip(\"_refined\")\n",
    "    target_dir = marker + \"/\"\n",
    "    save_dir = os.path.join(base_save_dir, marker)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        videos = json.load(f)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        url = video[\"video_url\"]\n",
    "        if not url.startswith(\"https://www.youtube.com/watch?v=\"):\n",
    "            continue\n",
    "        pruned_url, video_id = parse_url(url)\n",
    "        save_file = os.path.join(save_dir, video_id + \".mp4\")\n",
    "        if os.path.exists(save_file):\n",
    "            video_info = get_video_info(save_file)\n",
    "            if video_info[\"height\"] != 720 and video_info[\"width\"] != 1280:\n",
    "                with open(os.path.join(log_dir, \"resolution_error.log\"), \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"Resolution error detected in {save_file} with resolution of {video_info['width']}x{video_info['height']}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=17FGAMlypgrX3HNathX74LqISFn0Wtfde\n",
      "From (redirected): https://drive.google.com/uc?id=17FGAMlypgrX3HNathX74LqISFn0Wtfde&confirm=t&uuid=79d2ebb0-6728-4c71-834b-f82850af1c98\n",
      "To: /mnt/bn/videonasi18n/longlin.kylin/mmagent/data/videos/ZZ_5.zip\n",
      "100%|██████████| 2.39G/2.39G [00:42<00:00, 55.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/videos/ZZ_5.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = (\n",
    "    \"https://drive.google.com/file/d/17FGAMlypgrX3HNathX74LqISFn0Wtfde/view?usp=sharing\"\n",
    ")\n",
    "url = f\"https://drive.google.com/uc?id=17FGAMlypgrX3HNathX74LqISFn0Wtfde\"\n",
    "output = \"data/videos/ZZ_5.zip\"\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "7b0fb52d-85ad-4e88-a0d5-2d0406905f24",
  "filePath": "/mnt/bn/videonasi18n/longlin.kylin/mmagent/download.ipynb",
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
