{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from prompts import *\n",
    "import tempfile\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import base64\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path):\n",
    "    video_info = {}\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        raise ValueError(\"Could not open video file\")\n",
    "    video_info[\"fps\"] = video.get(cv2.CAP_PROP_FPS)\n",
    "    video_info[\"frames\"] = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_info[\"duration\"] = video_info[\"frames\"] / video_info[\"fps\"]\n",
    "    video_info[\"path\"] = video_path\n",
    "    video_info[\"name\"] = video_path.split(\"/\")[-1]\n",
    "    video_info[\"width\"] = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    video_info[\"height\"] = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_info[\"codec\"] = video.get(cv2.CAP_PROP_CODEC_PIXEL_FORMAT)\n",
    "    video_info[\"format\"] = video.get(cv2.CAP_PROP_FORMAT)\n",
    "    video_info[\"fourcc\"] = video.get(cv2.CAP_PROP_FOURCC)\n",
    "    video.release()\n",
    "\n",
    "    # print video info\n",
    "    print(video_info)\n",
    "\n",
    "    return video_info\n",
    "\n",
    "\n",
    "def extract_frames(video_path, start_time=None, interval=None, sample_fps=10):\n",
    "    video_info = get_video_info(video_path)\n",
    "    # if start_time and interval are not provided, sample the whole video at sample_fps\n",
    "    if start_time is None and interval is None:\n",
    "        start_time = 0\n",
    "        interval = video_info[\"duration\"]\n",
    "    video_fps = video_info[\"fps\"]\n",
    "    total_frames = video_info[\"frames\"]\n",
    "    frame_interval = int(video_fps / sample_fps)\n",
    "\n",
    "    frames = []\n",
    "    segment_video = cv2.VideoCapture(video_path)\n",
    "    segment_video.set(cv2.CAP_PROP_POS_FRAMES, int(start_time * video_fps))\n",
    "    end_frame = min(int((start_time + interval) * video_fps), total_frames)\n",
    "\n",
    "    for frame_idx in range(int(start_time * video_fps), end_frame, frame_interval):\n",
    "        segment_video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = segment_video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "    segment_video.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def process_video_clip(video_path, start_time, interval, fps):\n",
    "    try:\n",
    "        base64_data = {}\n",
    "        # Create temporary files\n",
    "        temp_files = {\n",
    "            \"video\": tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\"),\n",
    "            \"audio\": tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\"),\n",
    "        }\n",
    "        temp_paths = {k: f.name for k, f in temp_files.items()}\n",
    "        for f in temp_files.values():\n",
    "            f.close()\n",
    "\n",
    "        # Extract video segment\n",
    "        stream = ffmpeg.input(video_path, ss=start_time, t=interval)\n",
    "        stream = ffmpeg.output(\n",
    "            stream, temp_paths[\"video\"], format=\"mp4\", acodec=\"aac\", vcodec=\"libx264\"\n",
    "        )\n",
    "        ffmpeg.run(stream, overwrite_output=True)\n",
    "\n",
    "        # Extract audio\n",
    "        audio_stream = ffmpeg.input(temp_paths[\"video\"])\n",
    "        audio_stream = ffmpeg.output(\n",
    "            audio_stream, temp_paths[\"audio\"], acodec=\"libmp3lame\"\n",
    "        )\n",
    "        ffmpeg.run(audio_stream, overwrite_output=True)\n",
    "\n",
    "        # Read files and convert to Base64\n",
    "        for key, path in temp_paths.items():\n",
    "            with open(path, \"rb\") as f:\n",
    "                base64_data[key] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "            os.remove(path)\n",
    "\n",
    "        base64_data[\"frames\"] = extract_frames(video_path, start_time, interval, fps)\n",
    "\n",
    "        return base64_data[\"video\"], base64_data[\"frames\"], base64_data[\"audio\"]\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"FFmpeg Error:\", e.stderr.decode())\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(video_clips, qa, model):\n",
    "    question = qa[\"question\"]\n",
    "    gt = qa[\"answer\"]\n",
    "\n",
    "    inputs = [\n",
    "        [\n",
    "            {\"type\": \"video_base64\", \"content\": clip},\n",
    "            {\"type\": \"text\", \"content\": prompt_baseline_answer_clipwise_extract},\n",
    "            {\"type\": \"text\", \"content\": f\"Question: {question}\"},\n",
    "            {\"type\": \"text\", \"content\": \"Extracted information:\"},\n",
    "        ]\n",
    "        for clip in video_clips\n",
    "    ]\n",
    "    messages = [generate_messages(input) for input in inputs]\n",
    "    responses = parallel_get_response(model, messages)\n",
    "\n",
    "    extracted_information = [\n",
    "        response for response in responses[0] if not response.lower().startswith(\"none\")\n",
    "    ]\n",
    "    if len(extracted_information) == 0:\n",
    "        answer = \"Unanswerable.\"\n",
    "    else:\n",
    "        input = [\n",
    "            {\"type\": \"text\", \"content\": prompt_baseline_answer_clipwise_summarize},\n",
    "            {\"type\": \"text\", \"content\": f\"Question: {question}\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": f\"Extracted information: {extracted_information}\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"content\": \"Answer:\"},\n",
    "        ]\n",
    "        messages = generate_messages(input)\n",
    "        model = \"gpt-4o-2024-05-13\"\n",
    "        response = get_response_with_retry(model, messages)\n",
    "        answer = response[0]\n",
    "\n",
    "    qa[\"answer_baselines\"] = answer\n",
    "    return qa\n",
    "\n",
    "\n",
    "def verify_answers(qas):\n",
    "    inputs = [\n",
    "        [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": qa,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": prompt_benchmark_verify_answer,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": \"Now answer if the answer from the baseline is correct or not:\",\n",
    "            },\n",
    "        ]\n",
    "        for qa in qas\n",
    "    ]\n",
    "    messages = [generate_messages(input) for input in inputs]\n",
    "    model = \"gpt-4o-2024-05-13\"\n",
    "    responses = parallel_get_response(model, messages)\n",
    "\n",
    "    results = responses[0]\n",
    "\n",
    "    # calculate the accuracy of the answers\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.lower().startswith(\"yes\"):\n",
    "            correct += 1\n",
    "    accuracy = correct / len(results)\n",
    "\n",
    "    return accuracy, results\n",
    "\n",
    "\n",
    "def process_video(video_path, interval_seconds, fps, qa_list):\n",
    "    \"\"\"Process video segments at specified intervals with given fps.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file\n",
    "        interval_seconds (float): Time interval between segments in seconds\n",
    "        fps (float): Frames per second to extract from each segment\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    video_info = get_video_info(video_path)\n",
    "    print(video_info)\n",
    "\n",
    "    clips = []\n",
    "\n",
    "    # Process each interval\n",
    "    for start_time in np.arange(0, video_info[\"duration\"], interval_seconds):\n",
    "\n",
    "        base64_video, _, _ = process_video_clip(\n",
    "            video_path, start_time, interval_seconds, fps\n",
    "        )\n",
    "        clips.append(base64_video)\n",
    "\n",
    "    model = \"gemini-1.5-pro-002\"\n",
    "    qpm = config[model][\"qpm\"]\n",
    "    qa_batch_size = qpm // len(clips)\n",
    "    qa_batches = [\n",
    "        qa_list[i : i + qa_batch_size] for i in range(0, len(qa_list), qa_batch_size)\n",
    "    ]\n",
    "\n",
    "    answered_qa_list = []\n",
    "\n",
    "    for qa_batch in qa_batches:\n",
    "        # parallel question answering with multiple threads\n",
    "        with ThreadPoolExecutor(max_workers=len(qa_batch)) as executor:\n",
    "            futures = [\n",
    "                executor.submit(answer_question, clips, qa, model) for qa in qa_batch\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                qa = future.result()\n",
    "                answered_qa_list.append(qa)\n",
    "\n",
    "    return answered_qa_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
